\documentclass[a4paper]{article}

\input{temp}

\setcounter{section}{-1}

\begin{document}

\title{Analytic Number Theory}

\maketitle

\newpage

\tableofcontents

\newpage

\section{Introduction}

---Lecture 1---

Lecturer: Thomas Bloom ($tb634@cam.ac.uk$, $www.thomasbloom.org/ant.html$)

Printed notes will be updated, but 1-2 weeks behind.

Example classes: weeks 3,5,7, tuesdays 330-5pm; prop-in sessions weeks 2,4,6,8. Rooms to be confirmed later.

What is analytic number theory? It's the study of numbers (regular integers, discrete) using analysis (real/complex, continuous) and some other quantitative questions.

For example, for the famous function $\pi(x)$, the number of primes no greater than $x$, we know $\pi(x) \sim \frac{x}{\log x}$.

Throughout this course, by \emph{numbers} we'll mean natural numbers excluding 0.

We can also ask how many twin primes there are, i.e. how many $p$ such that $p,p+2$ are both prime. This is not known yet (not even the finiteness); but from 2014, Zhang, Maynard, Polymath showed that there are infinitely many primes at most 246 apart, which is not that far from 2. The current guess is that the number is around $\frac{x}{(\log x)^2}$.

Another question we may ask: how many primes are there $\equiv a \pmod q$, $(a,q) = 1$. We know by Dirichlet's theorem that there are infinitely many.\\
A natural guess of the count is $\frac{1}{\phi(q)} \frac{x}{\log x}$, where $\phi(x)$ is the Euler Totient function. This is known to hold for small $q$.

In this course we'll talk about:\\
(1) Elementary techniques (real analysis);\\
(2) Sieve methods;\\
(3) Riemann zeta function/prime number theory (complex analysis);\\
(4) Primes in arithmetic progressions.

\newpage

\section{Elementary techniques}
Review of asymptotic notation:\\
$\bullet$ $f(x) = O(g(x))$ if there is $c>0$ s.t. $|f(x)| \leq c|g(x)|$ for all large enough $x$;\\
$\bullet$ $f \ll g$ is the same thing as $f=O(g)$. This also defines what $f \gg g$ means in the natural way;\\
$\bullet$ $f \sim g$ if $\lim_{x \to \infty} \frac{f(x)}{g(x)} = 1$ (i.e. $f=(1+o(1))g$);\\
$\bullet$ $f=o(g)$ if $\lim_{x \to \infty} \frac{f(x)}{g(x)} = 0$.

\subsection{Arithmetic functions}
Arithmetic functions are just functions $f:\N \to \C$; in other words, relabelling natural numbers with some complex numbers.\\
An important operation for multiplicative number theory ($fg = f(n)g(n)$) is multiplicative convolution,
$$f*g(n) = \sum_{ab=n}f(a)g(b)$$

Examples: $1(n) \equiv 1 \forall n$ (caution: $1$ is not the identity function, and $1*f \neq f$).\\
M\"{o}bius function:
\begin{equation*}
\begin{aligned}
\mu(n) = \left\{\begin{array}{ll}
(-1)^k & \text{ if } n=p_1...p_k\\
0 & \text{ if } n \text{ is divisible by a square} 
\end{array}
\right.
\end{aligned}
\end{equation*}
Liouville function: $\lambda(n) = (-1)^k$ if $n=p_1...p_k$ (primes not necessarily distinct),\\
Divisor function: $\tau(n) = $ number of $d$ s.t. $d|n = \sum_{ab = n} 1 = 1*1$. This is sometimes also known as $d(n)$.

An arithmetic function is multiplicative if $f(nm) = f(n)f(m)$ when $(n,m)=1$.\\
In particular, a multiplicative function is determined by its values on prime powers.

\begin{fact}
If $f,g$ are multiplicative, then so is $f*g$.\\
All the function we've seen so far ($\mu,\lambda,\tau,1$) are multiplicative.
\end{fact}

Non-example: $\log n$ is definitely not multiplicative.

\begin{fact} (M\"{o}bius inversion)\\
$1*f=g \iff \mu*g=f$. That is,
$$\sum_{a|n} f(d) = g(n) \forall n \iff \sum_{d|n} g(d)\mu(n/d) = f(n) \forall n$$
e.g.
\begin{equation*}
\begin{aligned}
\sum_{d|n}\mu(d) = \left\{\begin{array}{ll}
1 & n=1\\
0 & \text{else}
\end{array}
\right. = 1*\mu
\end{aligned}
\end{equation*}
is multiplicative: it's enough to check identity for primes powers.\\
If $n=p^k$ then $\{d|n\} = \{1,p,...,p^k\}$. So LHS=$1-1+0+0+...=0$, unless $k=0$ when LHS = $\mu(1) = 1$.

Our goal is to study primes. The first guess might be to work with
\begin{equation*}
\begin{aligned}
1_p(n) = \left\{\begin{array}{ll}
1 & n \text{ prime}\\
0 & \text{else}
\end{array}
\right.
\end{aligned}
\end{equation*}
(e.g. $\pi(x) = \sum_{1 \leq n \leq x} 1_p(n)$). Instead, we work with von Mangoldt funcion
\begin{equation*}
\begin{aligned}
\wedge(n) = \left\{\begin{array}{ll}
\log p & n \text{ is a prime power}\\
0 & \text{else}
\end{array}
\right.
\end{aligned}
\end{equation*}
(e.g. in a few lectures we'll look at $\psi(x) = \sum_{1\leq n \leq x} \wedge(n)$).
\end{fact}

\begin{lemma} (1)\\
$1*\wedge = \log$, and by M\"{o}bius inversion, $\mu*\log = \wedge$.\\
Note that it's easy to realize that $\wedge$ is not multiplicative, else $\log$ will be.
\begin{proof}
$1*\wedge(n) = \sum_{d | n} \wedge(d)$. So if $n=p_1^{k_1}...p_r^{k_r}$, then above
\begin{equation*}
\begin{aligned}
&=\sum_{i=1}^r \sum_{j=1}^{k_i} \wedge(p_i^j)\\
&=\sum_{i=1}^r \sum_{j=1}^{k_i} \log(p_i)\\
&= \sum_{i=1}^r k_i \log (p_i)\\
&= \log n
\end{aligned}
\end{equation*}
\end{proof}
\end{lemma}

Note that the above tells us
\begin{equation*}
\begin{aligned}
\wedge(n) &= \sum_{d|n} \mu(d) \log(n/d)\\
&=\log n \sum_{d|n}\mu(d) - \sum_{d|n} \mu(d)\log d\\
&= -\sum_{d|n} \mu(d)\log d
\end{aligned}
\end{equation*}
by the famous fact that $\sum_{d|n}\mu(d)=0$ unless $n=1$; but when $n=1$, $\log n = 0$.\\
Now we can try to evaluate
\begin{equation*}
\begin{aligned}
-\sum_{1 \leq n \leq x} \wedge(n) &= \sum_{1 \leq n \leq x} \sum_{d|n} \mu(d) \log d \\
&= -\sum_{d \leq x} \mu(d) \log d (\sum_{1 \leq n \leq x, d|n} 1)\ \text{ (reverse order of summation)}
\end{aligned}
\end{equation*}
But
$$\sum_{1 \leq n \leq x, d|n} 1 = \lfloor x/d \rfloor = x/d + O(1)$$
So we know the original sum is equal to
$$-x\sum_{d \leq x} \mu(d) \frac{\log d}{d} + O(\sum_{d \leq x} \mu(d) \log d)$$

---Lecutre 2---

Lecturer's favourite book: \emph{Multiplicative Number Theory}.

Room for example classes: MR14 (Tues 330-5pm, week 357).

\subsection{Summation}
Given an arithmetic function $f$, we can ask for estimates of $\sum_{1 \leq n \leq x} f(n)$.\\
We say that $f$ has \emph{average order $g$} if $\sum_{1 \leq n \leq x} f(n) \sim xg(x)$ (in some sense, the average size of $f$ is $g$).

For example, if $f \equiv 1$, then $\sum_{1 \leq n \leq x} f(n) = \lfloor x \rfloor = x+O(1) \sim x$. So the average order of $1$ is $1$ (makes a lot of sense).\\
A slightly less trivial example is the identity function $f(n) = n$: we have $\sum_{1 \leq n \leq x} n \sim \frac{x^2}{2}$, so the average order of $n$ is $n/2$.

\begin{lemma} (1, Partial summation)\\
If $(a_n)$ is a sequence of complex numbers, and $f$ is s.t. $f'$ is continuous. Then $\sum_{1 \leq n \leq x} a_n f(n) = A(x) f(x) - \int_1^x A(t) f'(t) dt$, where $A(x) = \sum_{1 \leq n \leq x} a_n$.\\
We can see that this is a discrete version of integration by parts.
\begin{proof}
Suppose $x=N$ is an integer. Note that $a_n = A(n) - A(n-1)$. So
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq N} a_nf(n) &= \sum_{1 \leq n \leq N} f(n) (A(n)-A(n-1))\\
&= A(N)f(N) - \sum_{n=1}^{N-1}A(n) (f(n+1)-f(n)) \text{ using } A(0)=0
\end{aligned}
\end{equation*}
Now $f(n+1)-f(n) = \int_n^{n+1} f'(t)dt$. So
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq N} a_n f(n) &= A(N)f(N) - \sum_{n=1}^{N-1} A(n) \int_n^{n+1} f'(t) dt\\
&= A(N)f(N) - \int_1^N A(t) f'(t) dt
\end{aligned}
\end{equation*}
To be complete, we should also consider the case where $x$ is not an integer. But if $N=\lfloor x \rfloor$,
\begin{equation*}
\begin{aligned}
A(x) f(x) &= A(N)f(x)\\
&=A(N)\left(f(N)+\int_N^x f'(t)dt\right)
\end{aligned}
\end{equation*}
\end{proof}
\end{lemma}

\begin{lemma} (2)\\
$$\sum_{1 \leq n \leq x} \frac{1}{n} = \log x + \gamma + O\left(\frac{1}{x}\right)$$
where $\gamma$ is some constant.
\begin{proof}
Apply partial summation with $f(x)=\frac{1}{x}$ and $a_n \equiv 1$, so $A(x) = \lfloor x \rfloor$. Then, writing $\lfloor t \rfloor = t - \{t\}$,
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq x} \frac{1}{n} &= \frac{\lfloor x \rfloor}{x} + \int_1^x \frac{\lfloor t \rfloor}{t^2} dt\\
&= 1 + O\left(\frac{1}{x}\right) + \int_1^x \frac{1}{t} dt - \int_1^x \frac{\{t\}}{t^2} dt\\
&= 1+O\left(\frac{1}{x}\right) + \log x - \int_1^\infty \frac{\{t\}}{t^2} dt + \int_x^\infty \frac{\{t\}}{t^2} dt\\
&=\gamma + O\left(\frac{1}{x}\right) + \log x + O\left(\frac{1}{x}\right)\\
&= \log x + \gamma + O\left(\frac{1}{x}\right)
\end{aligned}
\end{equation*}
where at the penultimate step we bound the error term by 
\begin{equation*}
\begin{aligned}
\int_x^\infty \frac{\{t\}}{t^2} dt &\leq \int_x^\infty \frac{1}{t^2} dt\\
&\leq \frac{1}{x}
\end{aligned}
\end{equation*}
and we actually know $\gamma = 1 - \int_1^\infty \frac{\{t\}}{t^2} dt$.\\
This $\gamma$ is called Euler's constant (Euler-Mascheroni).\\
We know very little about this constant: we only know $\gamma=0.577...$, and we don't even know if $\gamma$ is irrational.
\end{proof}
\end{lemma}

\begin{lemma} (3)\\
$$\sum_{1 \leq n \leq x} \log n = x\log x - x + O(\log x)$$
\begin{proof}
Use partial summation again, with $f(x) = \log x$ and $a_n=1$, so $A(x) = \lfloor x \rfloor$:
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq x} \log n &= \lfloor x \rfloor \log x - \int_1^x \frac{\lfloor t \rfloor}{t} dt\\
&= x \log x + O(\log x) - \int_1^x 1 dt + O(\int_1^x \frac{1}{t} dt)\\
&= x\log x - x + O(\log x)
\end{aligned}
\end{equation*}
\end{proof}
\end{lemma}

\subsection{Dinsar function}
Recall that $\tau(n) = 1*1(n) =\sum_{d|n} 1$.

\begin{thm} (4)\\
$$\sum_{1 \leq n \leq x} \tau(n) = x\log x + (2\gamma - 1) x + O(x^{1/2})$$
So average order of $\tau$ is $\log x$.
\begin{proof}
Note that we won't apply partial summation here: PS allows to get $\sum a_n f(n)$ from knowledge of $\sum a_n$; but $\tau(n)$ here is not differentiable, so PS is not going to apply.
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq x} \tau(n) &= \sum_{1 \leq n \leq x} \sum_{d|n} 1\\
&= \sum_{1 \leq d \leq x} \sum_{1 \leq n \leq x, d|n} 1\\
&= \sum_{1 \leq d \leq x} \lfloor \frac{x}{d} \rfloor\\
&= \sum_{1 \leq d \leq x} \frac{x}{d} + O(x)\\
&= x \sum_{1 \leq d \leq x} \frac{1}{d} + O(x)\\
&= x\log x + \gamma x + O(x) 
\end{aligned}
\end{equation*}
where we applied lemma 2 at the last step. This is all correct, but the error term is larger than what we wanted. However, we have indeed prove that the average order of $\tau(x)$ is $\log x$.\\
To reduce error term, we use (Dirichlet's) hyperbola trick:
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq x} \tau(n) &= \sum_{1 \leq n \leq x} \sum_{ab = n} 1\\
&= \sum_{ab \leq x} 1\\
&= \sum_{a \leq x} \sum_{b \leq \frac{x}{a}} 1
\end{aligned}
\end{equation*}
Note that now we're just counting number of integer points below the hyperbola $xy=n$ (relabelling variables).\\
When summing over $ab \leq x$, we can sum over $a,b \leq x^{1/2}$ separately, then subtract the repetition off. Then
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq x} \tau (n) &= \sum_{a \leq x^{1/2}}\sum_{b \leq \frac{x}{a}} 1 + \sum_{b \leq x^{1/2}} \sum_{a \leq \frac{x}{b}} 1 - \sum_{a,b \leq x^{1/2}} 1\\
&= 2 \sum_{a \leq x^{1/2}} \lfloor \frac{x}{a} \rfloor - \lfloor x^{1/2} \rfloor^2\\
&= 2 \sum_{a \leq x^{1/2}} \frac{x}{a} + O(x^{1/2}) - x + O(x^{1/2})
\end{aligned}
\end{equation*}
by noting that $\lfloor x^{1/2}\rfloor^2 = (x^{1/2} + O(1))^2$. Now the above equals
\begin{equation*}
\begin{aligned}
&=2x\log x^{1/2} + 2\gamma x - x + O(x^{1/2})\\
&= x\log x + (2\gamma-1) x + O(x^{1/2})
\end{aligned}
\end{equation*}
\end{proof}

Improving this $O(x^{1/2})$ error term is a famous and hard problem. We should probably get $O(x^{1/4+\varepsilon})$, but this is open. The best known result is $O(x^{0.3149...})$.
\end{thm}

Note that this does \emph{not} mean that $\tau(n) \ll \log n$. The average order is small doesn't say about the individual values being small.

We'll state the theorem we're proving and prove it in the next lecture:
\begin{thm} (5)\\
$$\tau(n) \leq n^{O(\frac{1}{\log\log n})}$$
In particular, $\tau(n) \ll_\varepsilon n^\varepsilon$ $\forall \varepsilon > 0$.

---Lecture 3---
\begin{proof}
    $\tau$ is multiplicative, so it's enough to calculate at prime powers.\\
    Now, $\tau(p^k) = k+1$. So if $n=p_1^{k_1}...p_r^{k_r}$, thjen $\tau(n) = \prod_{i=1}^r (k_i+1)$.\\
    Let $\varepsilon$ be chosen later, and consider $\frac{\tau(n)}{n^\varepsilon} = \prod_{i=1}^r \frac{k_i+1}{p_i^{k_i\varepsilon}}$. Note as $p \to \infty$, $\frac{k+1}{p^{k\varepsilon}} \to 0$.\\
    In particular, if $p \geq 2^{1/\varepsilon}$, then $\frac{k+1}{p^{k\varepsilon}} \leq \frac{k+1}{2^k} \leq 1$. What about for small $p$? We can't do better than $p \geq 2$, but that's enough.\\
    In this case, $\frac{k+1}{p^{k\varepsilon}} \leq \frac{k+1}{2^{k\varepsilon}} \leq \frac{1}{\varepsilon}$ (as $x+\frac{1}{2} \leq 2^x \implies \varepsilon k + \varepsilon \leq 2^{k\varepsilon} \forall x \geq 0$), for $\varepsilon \leq 1/2$.\\
    So
    \[
        \frac{\tau(n)}{n^\varepsilon} \leq \prod_{i=1,_i < 2^{1/\varepsilon}}^r \frac{k_i+1}{p^{k_i \varepsilon}} \leq (1/\varepsilon)2^{1/\varepsilon}
    \]
    Now choose optimal $\varepsilon$:\\
    (trick!) if you want to choose $x$ to minimise $f(x)+g(x)$, choose $x$ s.t. $f(x) = g(x)$.\\
    So here, $\tau(n) \leq n^\varepsilon \varepsilon^{-2^{1/\varepsilon}} = exp(\varepsilon \log n + 2^{1/\varepsilon} \log 1/\varepsilon)$.\\
    Choose $\varepsilon$ s.t. $\log n \approx 2^{1/\varepsilon}$, i.e. $\varepsilon = \frac{1}{\log\log n}$. So
    \[
        \tau(n) &\leq n^{1/\log\log n} (\log\log n)^{2^{\log\log n}}\\
        &= n^{1/\log\log n} e^{(\log n)^{\log 2} \log \log \log n}\\
        &\leq n^{O(\frac{1}{\log \log n})} 
    \]
\end{proof}
\end{thm}

\subsection{Estimates for the Primes}

Recall $\pi(x)$ is the number of primes $\leq x = \sum_{1 \leq n \leq x} 1_p(n)$, and $\psi(x) = \sum_{1 \leq n \leq x} \Lambda(n)$. The prime number theorem states that $\pi(x) \sim \frac{x}{\log x}$, or equivalently $\psi(x) \sim x$ (justified later).\\
It was 1850 before the correct magnitude of $\pi(x)$ was proved. Chebyshev showed that $\pi(x) \asymp x/\log x$, where $f \asymp g$ means $g \ll f \ll g$.

\begin{thm} (6, Chebyshev)\\
    $\psi(x) \asymp x$.\\
    We'll show below that $(\log 2) x \leq \psi(x) \leq (\log 4) x$ (remember that the default base for $\log$ is $e$, so $\log 2 < 1$ while $\log 4 > 1$).
    \begin{proof}
        First we'll prove the lower bound. Recall $1 *\Lambda = \log$, i.e. $\sum_{ab = n} \Lambda(a) = \log n$. The (genuine) trick is to find a sum $\Sigma$ s.t. $\varepsilon \leq 1$(?). We'll use the identity $\lfloor x \rfloor \leq 2 \lfloor \frac{x}{2} \rfloor + 1 \forall x \geq 0$. Why? Say $\frac{x}{2} = n+\theta$, $\theta \in [0,1)$ Then $\lfloor \frac{x}{2} \rfloor = n$, and $x = 2n+2\theta$, and so $\lfloor x \rfloor = 2n$, or at most $2n+1$.\\
        So
        \[
            \psi(x) &\geq \sum_{n \leq x} \Lambda(n) (\lfloor \frac{x}{n} \rfloor - 2\lfloor \frac{x}{2n} \rfloor)\\
            &= \sum_{n \leq x} \Lambda(n) \sum_{m \leq x/n} 1 - 2 \sum_{n \leq x} \Lambda(n) \sum_{m \leq \frac{x}{2n}} 1\\
            &= \sum_{nm \leq x} \Lambda(n) - 2\sum_{nm \leq x/2} \Lambda(n), \text{ write } d = nm,\\
            &= \sum_{d \leq x} 1 *\Lambda(d) - 2 \sum_{d \leq x/2} 1 * \Lambda(d)\\
            &= \sum_{d \leq x} \log d - 2 \sum_{d \leq x/2} \log d\\
            &=x\log x - x + O(\log x) - 2(\frac{x}{2} \log \frac{x}{2} - \frac{x}{2} + O(\log x))\\
            &= (\log 2) x + O(\log x) \gg x
        \]
        For the upper bound, note that $\lfloor x \rfloor = 2\lfloor x/2 \rfloor + 1$ for $x \in (1,2)$, so
        $$\sum_{x/2 < n < x} \Lambda(n) = \sum_{x/2 < n < x} \Lambda(n) (\lfloor x/n \rfloor - 2 \lfloor x/2n \rfloor) \leq \sum_{1 \leq n \leq x} \Lambda(n) (\lfloor x/n \rfloor - 2\lfloor x/2n \rfloor)$$
        so $\psi(x) - \psi(x/2) \leq (\log 2) x + O(\log x)$.\\
        So $\psi(x) = (\psi(x) - \psi(x/2)) + (\psi(x/2)-\psi(x/4))+... \leq \log 2 (x+x/2+x/4+...) = (2\log 2) x$ (note only $\log x$ error terms at most).
    \end{proof}
\end{thm}

\begin{lemma} (7)\\
    \[
        \sum_{p \leq x, p \text{ primes}} \frac{\log p}{p} = \log x + O(1)
    \]
    \begin{proof}
        Recall that $\log = 1 * \Lambda$. So
        \[
            \sum_{n \leq x} \log n &= \sum_{ab \leq x} \Lambda(a)\\
            &= \sum_{a \leq x} \Lambda(a) \sum_{b \leq x/a} 1\\
            &= \sum_{a \leq x} \Lambda(a) \lfloor x/a \rfloor \\
            &= x \sum_{a \leq x} \frac{\Lambda(a)}{a} + O(\psi(x))\\
            &= x \sum_{a \leq x} \frac{\Lambda(a)}{a} + O(x)
        \]
        But $\sum_{n \leq x} \log n = x\log x - x + O(\log x)$. So
        \[
            \sum_{n \leq x} \frac{\Lambda(n)}{n} = \log x - 1 + O(\frac{\log x}{x}) + O(1) + \log x + O(1)
        \]
        It remains to note that 
        \[
            \sum_{p \leq x}\sum_{n=2}^\infty \frac{\log p}{p^n} &= \sum_{p \leq x} \log p \sum_{k=2}^\infty \frac{1}{p^k} \\
            &= \sum_{p \leq x} \frac{\log p}{p^2-p}\\
            &\leq \sum_{p=2}^\infty \frac{1}{p^{3/2}} = O(1)
        \]
        So $\sum_{n \leq x} \frac{\Lambda(n)}{n} = \sum_{p \leq x} \frac{\log p}{p}+O(1)$.
    \end{proof}
\end{lemma}

---Lecture 4---

Drop-in: Tuesday 4pm-5pm.

\begin{lemma} (8)\\
$\pi(x) = \frac{\psi(x)}{\log x} + O(\frac{x}{(\log x)^2})$.\\
In particular, $\pi(x) \asymp \frac{x}{\log x}$ and prime number theorem: $\pi(x) \sim \frac{x}{\log x}$ is equivalent to $\psi(x) \sim x$.\\
So from now on, we'll call this the prime number theorem instead.
\begin{proof}
The idea is to use partial summation:
\[
\theta(x) := \sum_{p \leq x} \log p &= \pi(x) \log x - \int_1^x \frac{\pi(t)}{t} dt
\]
but this doesn't work immediately, since $\psi(x) = \sum_{n \leq x} \Lambda(n) = \sum_{p^k \leq x} \log p$. However, we have
\[
\psi(x)-\theta(x) &= \sum_{k=2}^\infty \sum_{p^k \leq x} \log p\\
&= \sum_{k=2}^\infty \theta(x^{1/k})\\
&\leq \sum_{k=2}^\infty \psi(x^{1/k})\\
&= \sum_{k=2}^{\log x} \psi(x^{1/k})
\]
as the larger terms are all zero. Then the above
\[
\ll \sum_{k=2}^{\log x} x^{1/k}\\
\ll x^{1/2} \log x
\]
(Obviously we could do better, but that's less important). Now $\psi(x) = \pi(x) \log x + O(x^{1/2} \log x) - \int_1^x \frac{\pi(t)}{t} dt$. Note that we have $\pi(t) \ll \frac{t}{\log t}$, so we can bound the above by 
\[
\psi(x) &= \pi(x)\log x + O(x^{1/2} \log x) + O(\int_1^x \frac{1}{\log t} dt)\\
&= \pi(x) \log x+O(\frac{x}{\log x})
\]
(For $\pi(t) \ll \frac{t}{\log t}$, note that from $\pi(t) \leq t$, $\psi(x) = \pi(x)\log x + O(x^{1/2}\log x) + O(x)$. So $\pi(x) \log x = O(x)$).
\end{proof}
\end{lemma}

\begin{lemma} (9)\\
$\sum_{p \leq x} \frac{1}{p} = \log\log x + b + O(\frac{1}{\log x})$, where $b$ is some constant.
\begin{proof}
We use partial summation. Let $A(x) = \sum_{p \leq x} \frac{\log p}{p} = \log x + R(x)$ (so $R(x) \ll 1$ (by lemma 7)). Then
\[
\sum_{2 \leq p \leq x} \frac{1}{p} &= \frac{A(x)}{\log x} - \int_2^x \frac{A(t)}{t(\log t)^2} dt\\
&= 1 + O(\frac{1}{\log x}) + \int_2^x \frac{1}{t\log t} dt + \int_2^x \frac{R(t)}{t(\log t)^2} dt
\]
Note $\int_2^\infty \frac{R(t)}{t(\log t)^2} dt$ exists, say $=c$. Then
\[
\sum_{2 \leq p \leq x} \frac{1}{p} &= 1+c+O(\frac{1}{\log x}) + \log \log x - \log \log 2 + O(\int_x^\infty \frac{1}{t(\log t)^2} dt)\\
&= \log \log x + b + O(\frac{1}{\log x})
\]
\end{proof}
\end{lemma} 

\begin{thm} (10, Chebyshev)\\
If $\pi(x) \sim c \frac{x}{\log x}$, then $c=1$.\\
Note that this is weaker than PNT itself: this only says that \emph{if} that relation exists, then we must have $c=1$.\\
(Also, if $\pi(x) \sim \frac{x}{\log x - A(x)}$, then $A\sim 1$)
\begin{proof}
Use partial summation on $\sum_{p \leq x} \frac{1}{p}$:
\[
\sum_{p \leq x} \frac{1}{p} = \frac{\pi(x)}{x} - \int_1^x \frac{\pi(t)}{t^2} dt
\]
If $\pi(x) = (c+o(1)) \frac{x}{\log x}$, then
\[
&= \frac{c}{\log x} + o(\frac{1}{\log x}) + (c+o(1)) \int_1^x \frac{1}{t\log t} dt\\
&= O(\frac{1}{\log x}) + (c+o(1)) \log \log x
\]
But $\sum_{p \leq x} \frac{1}{p} = (1+o(1))\log x$. Hence $c=1$.
\end{proof}
\end{thm}

\begin{lemma} (11)\\
$\prod_{p \leq x} (1-\frac{1}{p})^{-1} = c\log x + O(1)$, where $c$ is some constant.
\begin{proof}
\[
\log (\prod_{p \leq x} (1-\frac{1}{p})^{-1}) &= -\sum_{p \leq x} (1-\frac{1}{p})\\
&= \sum_{p \leq x} \sum_k \frac{1}{kp^k}\\
&= \sum_{p \leq x} \frac{1}{p} + \sum_{k \geq 2} \sum_{p \leq x} \frac{1}{kp^k}\\
&=\log \log x + c' + O(\frac{1}{\log x})
\]
where we used the expansion $\log(1-t) = -\sum_k \frac{t^k}{k}$.\\
Now note that $e^x = 1 + O(x)$ for $|x| \leq 1$. So
\[
\prod_{p \leq x} (1-\frac{1}{p})^{-1} &= c\log x e^{O(\frac{1}{\log x})}\\
&= c\log x(1+O(\frac{1}{\log x}))\\
&= c\log x + O(1)
\]
\end{proof}
\end{lemma}
It turns out that $c=e^\gamma \approx 1.78...$, where $\gamma$ is the Euler constant that we've seen previously.

So why is PNT hard, given that we've proved so many results? From probabilistic heuristic, we have the 'probability' that $p|n$ is $\frac{1}{p}$.\\
What is the probability that $n$ is prime then? $n$ is prime iff $n$ has no prime divisors $\leq n^{1/2}$. Our guess is that the events 'divisible by $p$' are independent, so the probability that $n$ is prime should be something like $\prod_{p \leq n^{1/2}}(1-\frac{1}{p}) \approx \frac{1}{c \log n^{1/2}} = \frac{2}{c} \frac{1}{\log n}$. So
\[
\pi(x) = \sum_{n \leq x} 1_{n \ prime} \approx \frac{2}{c} \sum_{n \leq x} \frac{1}{\log n} \approx \frac{2}{c} \frac{x}{\log x} \approx 2 e^{-\gamma} \frac{x}{\log x}
\]
if the above guesses are correct; but from theorem 10 we know that the constant should be 1 instead of $2e^{-\gamma} \approx 1.122...$.\\
What have gone wrong? It turns out that the error terms accumulated are too overwhelming that they've actually contributed to the main term. So PNT is not something like we find the main term and prove that the error terms are negligible.

Recall that $1*\Lambda = \log$, so $\mu *\log = \Lambda$. So
\[
\psi(x) &= \sum_{n \leq x} \Lambda(n)\\
&= \sum_{ab \leq x} \mu(a) \log b\\
&= \sum_{a \leq x} \mu(a) (\sum_{b \leq \frac{x}{a}} \log b)
\]

Recall that
\[
\sum_{m \leq x} \log m &= x \log x - x + O(\log x),\\
\sum_{m \leq x} \tau(m) &= x\log x + (2\gamma - 1) x + O(x^{1/2})
\]
so their main terms agree.\\
So 
\[
\psi(x) &= \sum_{a \leq x} \mu(a) \left(\sum_{b \leq \frac{x}{a}} \tau(b) + 2\gamma \frac{x}{a} + O\left(\frac{x^{1/2}}{a^{1/2}}\right)\right)\\
&= \sum_{ab \leq x} \mu(a) \tau(b)\\
&= \sum_{abc \leq x} \mu(a)\\
&= \sum_{b \leq x} \sum_{ac \leq x/b} \mu(a)\\
&= \sum_{b \leq x} \sum_{d \leq x/b} \mu * 1(d)\\
&= \lfloor x \rfloor = x+O(1)
\]
since we know the last term is $0$ unless $d$ is 1.

The error term:
\[
-2\gamma \sum_{a \leq x} \mu(a) \frac{x}{a} = O(x \sum_{a \leq x} \frac{\mu(a)}{a})
\]
so we need to show that $\sum_{a \leq x} \frac{\mu(a)}{a} = o(1)$. However, this is still the same as PNT, so we haven't gained anything.

---Lecture 5---

\subsection{Selberg's identity, and an elementary proof of the PNT}

Recall that PNT is 
$$\psi(x) = \sum_{n \leq x} \Lambda(n) = x+o(x)$$

Let (\emph{Selberg's function})
$$\Lambda_2(n) = \mu*(\log^2)(n) = \sum_{ab = n} \mu(a) (\log b)^2$$
(Recall $\Lambda = \mu*\log$).

The idea is to prove a 'PNT for $\Lambda_2$' with elementary methods.

\begin{lemma} (12)\\
(1) $\Lambda_2(n) = \Lambda(n) \log n + \Lambda * \Lambda (n)$;\\
(2) $0 \leq \Lambda_2(n) \leq (\log n)^2$;\\
(3) If $\Lambda_2(n) \neq 0$, then $n$ has at most 2 distinct prime factors.
\begin{proof}
For (1), we use M\"{o}bius inverison, so it is enough to show that
\[
\sum_{d|n} (\Lambda(d) \log d + \Lambda * \Lambda(d)) &= (\log n)^2\\
&= \sum_{d | n} \Lambda(d) \log d + \sum_{ab | n} \Lambda(a) \Lambda(b) \text{ as } 1*\Lambda = \log\\
&= \sum_{d|n}\Lambda(d) \log d + \sum_{a|n} \Lambda(a)\underbrace{\left(\sum_{b|\frac{n}{a}} \Lambda(b))\right)}_{=\log(\frac{n}{d})}\\
&=\sum_{d|n} \Lambda(d) \log d + \sum_{d|n} \Lambda(d) \log (\frac{n}{d})\\
&= \log n \sum_{d|n} \Lambda(d) = (\log n)^2
\]
For (2), $\Lambda_2(n) \geq 0$ since both terms on RHS in (1) are $\geq 0$, and since $\sum_{d|n} \Lambda_2(d) = (\log n)^2$, $\Lambda_2(n) \leq (\log n)^2$.\\
For (3), note that if $n$ is divisible by 3 distinct primes, then $\Lambda(n) = 0$, and $\Lambda *\Lambda(n) = \sum_{ab = n} \Lambda(a)\Lambda(b) = 0$ since at least one of $a$ or $b$ has $\geq 2$ distinct prime divisors.
\end{proof}
\end{lemma}

\begin{thm} (13, Selberg)\\
\[
\sum_{n \leq x} \Lambda_2(n) = 2x\log x + O(x)
\]
\begin{proof}
\[
\sum_{n \leq x} \Lambda_2(n) &= \sum_{n \leq x} \mu*(\log)^2(n)\\
&= \sum_{ab \leq x} \mu(a)(\log b)^2\\
&= \sum_{a \leq x} \mu(a) \left(\sum_{b \leq \frac{x}{a}}(\log b)^2\right)
\]
By PS,
\[
\sum_{m \leq x} (\log m)^2 = x (\log x)^2 - 2x\log x + 2x + O((\log x)^2)
\]
By PS, (let $A(t) = \sum_{n \leq t} \tau(n) = t\log t + ct + O(t^{1/2})$)
\[
\sum_{m \leq x} \frac{\tau(m)}{m} &= \frac{A(x)}{x} + \int_1^x \frac{A(t)}{t^2} dt\\
&=\log x + c + O(x^{-1/2}) + \int_1^x \frac{\log t}{t} dt + c\int_1^x\frac{1}{t} dt + O(\int_1^x \frac{1}{t^{3/2}} dt)\\
&= \frac{(\log x)^2}{2} + c_1 \log x + c_2 + O(x^{-1/2})
\]
So
\[
\frac{x(\log x)^2}{2} = \sum_{m \leq x} \tau(m) \frac{x}{m} + c_1' \sum_{m \leq x} \tau(m) + c_2'x + O(x^{1/2})
\]
So
\[
\sum_{n \leq x} (\log m)^2 = 2\sum_{m \leq x} \tau(m) \frac{x}{m} + c_3 \sum_{m \leq x} \tau(m) + c_4 x + O(x^{1/2})
\]
So
\[
\sum_{n \leq x} \Lambda_2(n) = 2 \sum_{a \leq x} \mu(a) \sum_{b \leq \frac{x}{a}} \frac{\tau(b) x}{ab} + c_5 \sum_{a \leq x} \mu(a) \sum_{b \leq \frac{x}{a}} \tau(b) + c_6 \sum_{a \leq x} \mu(a) \frac{x}{a} + O(\sum_{a \leq x} \frac{x^{1/2}}{a^{1/2}})
\]
First, note that $x^{1/2} \sum_{a \leq x} \frac{1}{a^{1/2}} = O(x)$ (by PS or just comparing with the integral. Secondly,
\[
x \sum_{a \leq x} \frac{\mu(a)}{a} &= \sum_{a \leq x} \mu(a) \lfloor \frac{x}{a} \rfloor + O(x)\\
&= \sum_{a \leq x} \mu(a) \sum_{b \leq \frac{x}{a}} 1 + O(x)\\
&= \sum_{d \leq x} \mu*1 (d) + O(x)\\
&= O(x)
\]
since the sum is either 1 (when $d=1$) or 0 (otherwise).\\
Thirdly,\footnote{Jaspal noticed that this can be obtained much more easily by $\mu*\tau = 1$ from M\"{o}bius inversion.}
\[
\sum_{a \leq x} \mu(a) \sum_{b \leq x} \tau(b) &= \sum_{a\leq x} \mu(a) \sum_{b \leq \frac{x}{a}} \sum_{cd = b} 1\\
&= \sum_{a \leq x} \mu(a) \sum_{cd \leq \frac{x}{a}}1\\
&= \sum_{acd \leq x} \mu(a)\\
&= \sum_{d \leq x} \sum_{ac \leq \frac{x}{d}} \mu(a)\\
&= \sum_{d \leq x} \sum_{e \leq \frac{x}{d}} \mu* 1(e)\\
&= \sum_{d \leq x} 1 = O(x)
\]
So
\[
\sum_{n \leq x} \Lambda_2(n) &= 2\sum_{a \leq x} \mu(a) \sum_{b \leq \frac{x}{a}} \frac{\tau(b)x}{ab} + O(x)\\
&= 2x \sum_{d \leq x} \frac{1}{d} \mu * \tau(d) + O(x)
\]
Recall that $\tau = 1*1$, so $\mu *\tau = \mu*1*1=1$. So the above
\[
&= 2x \sum_{d \leq x} \frac{1}{d} + O(x)\\
&= 2x \log x + O(x)
\]
\end{proof}
\end{thm}

(Non-examinable from now, but lecturer still recommends us to think about it)\\
A 14-point plan to prove PNT from Selberg's identity:\\
Let $r(x) = \frac{\psi(x)}{x} - 1$, so PNT is equivalent to $\lim_{x \to \infty} |r(x)| = 0$.\\
1) Selberg's identity $\implies$
\[
r(x) \log x = -\sum_{n \leq x} \frac{\Lambda(n)}{n} r(\frac{x}{n}) + O(1)
\]
2) Considering 1) with $x$ replaced $\frac{x}{m}$, summing over $m$, show 
\[
|r(x)|(\log x)^2 \leq \sum_{n \leq x} \frac{\Lambda_2(n)}{n} |r(\frac{x}{n})| + O(\log x)
\]
3) 
\[
\sum_{n \leq x} \Lambda_2(n) = 2\int_1^{\lfloor x \rfloor} \log t dt + O(x)
\]
4-6) (Let's skip some of the steps)
\[
\sum_{n \leq x} \frac{\Lambda_2(n)}{n} |r(\frac{x}{n})| = 2\int_1^x \frac{|r(x/t)|}{t\log t} dt + O(\log x)
\]
7) Let $V(u) = r(e^u)$. Show that 
\[
u^2 |V(u)| \leq 2 \int_0^u \int_0^v |V(t)| dt dv + O(u)
\]
8) Show
\[
\limsup|r(x)| \leq \limsup \frac{1}{u} \int_0^u |V(t)| dt = \beta
\]
9-14) (!) If $\alpha>0$, then can show from 7) that $\beta < \alpha$, contradiction; so $\alpha=0$, and PNT.

\newpage

\section{Sieve Methods}

---Lecture 6---

Hand in by Monday if you want some questions (q2 and q3) to be marked.

Everyone knows how Sieve of Eratosthenes works (some demonstration by lecturer). Our interest is in using the sieve to \emph{count} things. If we apply Sieve of Eratosthenes to the interval $[1,20]$, then we get an equality between two ways of counting how many numbers are left:
\[
\pi(20)+1-\pi(\sqrt{20}) = 20-\lfloor 20/2\rfloor - \lfloor 20/3\rfloor + \lfloor 20/6\rfloor
\]
where both sides evaluate to 7.

\subsection{Setup}
We'll have the following:\\
$\bullet$ Finite set $A \subset \N$ (the set to be sifted);\\
$\bullet$ Set of primes $p$ (the set of primes we sift out by), usually all primes;\\
$\bullet$ Sifting limit $z$ (sift all primes in $P$ less than $z$)\\
$\bullet$ sifting function
\[
S(A,P;z) = \sum_{n \in A} 1_{(n,\prod_{p \in P, p < z}p) =1}
\]

Let $\prod_{p \in P, p < z} p = P(z)$. Our goal is to estimate $S(A,P;z)$.

$\bullet$ For $d$, let
\[
A_d = \{n \in A:d | n\}
\]
$\bullet$ We write $|A_d| = \frac{f(d)}{d} X + R_d$ (most textbooks use $\omega$ in place of $f$ here, our use here is to avoid confusion), where $f$ is multiplicative ($f(mn) = f(m) f(n) \forall (m,n)=1$), and $0 \leq f(d) \forall d$.\\
$\bullet$ Note that $|A| = \frac{f(1)}{1} X + R_1 = X+R_1$;\\
$\bullet$ $R_d$ is an 'error' term;\\
$\bullet$ We choose $f$ so that $f(p) = 0$ if $p \not\in P$ by convention (so in that case $R_p = |A_p|$).\\
$\bullet$ Let $W_p(z) = \prod_{p < z, p \in P} (1-\frac{f(p)}{p})$.

\begin{eg}
1) Take $A=(x,x+y] \cap \N$, $P$ the set of all primes. So $|A_d| = \lfloor \frac{x+y}{d} \rfloor - \lfloor \frac{x}{d}\rfloor = \frac{y}{d} + O(1)$.\\
Here $f(d) \equiv 1$, and $R_d = O(1)$.\\
So $S(A,P;z)= |\{x < n \leq x+y: p | n \implies p \geq z\}|$.\\
e.g. if $z \approx (x+y)^{1/2}$, then
\[
S(A,P;z) = \pi(x+y)-\pi(x) + O((x+y)^{1/2})
\]
\end{eg}

2) $A = \{1 \leq n \leq y: n \equiv a \pmod q\}$, $A_d = \{1 \leq m \leq \frac{x}{d}: dm \equiv a \pmod q\}$. This congruence only has solutions if $(d,q) | a$. So \\
$|A_d| = \frac{(d,q)}{dq} y + O((d,q))$ if $(d,q) | a$, and $=O((d,q))$ otherwise.\\
So here $X=y/q$, and $f(d) = d(d,q)$ if $(d,q) | a$, and $0$ otherwise.

3) How about twin primes, i.e. $p,p+2$ both primes? We have\\
$A=\{n(n+2): 1 \leq n \leq x\}$ (so if $p|n(n+2) \iff n \equiv 0,-2 \pmod p$);\\
$P$ is all primes except 2;\\
$|A_p| = \frac{2x}{p} + O(1)$ (so $f(p) = 2$). So $f(d) = 2^{\omega(d)}$ for $f$ to be completely multiplicative, where $\omega(d)$ denote the number of primes divisors of $d$.\\
$S(A,P;x^{1/2}) = |\{1 \leq p \leq x: p,p+2$ both prime$\} + O(x^{1/2})$. Denote the main term as $\pi_2(x)$, then as mentioned in the first lecture we expect $\pi_2(x) \approx \frac{x}{(\log x)^2}$. We will prove the upper bound using sieves.

\begin{thm} (1, Sieve of Eratosthenes Legendre)\\
$S(A,P;z) = X W_p(z) + O (\sum_{d | p(z)} R_d)$.
\begin{proof}
\[
S(A,P;z) &= \sum_{n \in A} 1_{(n,p(z)) = 1}\\
&= \sum_{n \in A} \sum_{d | (n,p(z))} \mu(d)\\
&= \sum_{n \in A} \sum_{d | n,d|p(z)} \mu(d)\\
&= \sum_{d | p(z)} \mu(d) \sum_{n \in A} 1_{d|n}\\
&= \sum_{d | p(z)} \mu(d) |A_d|\\
&= X \sum_{d | p(z)} \frac{\mu(d)f(d)}{d} + \sum_{d | p(z)} \mu(d) R_d\\
&= X \prod_{p \in P, p < z} \left(1-\frac{f(p)}{p}\right) + O(\sum_{d | p(z)} |R_d|)
\]
\end{proof}
\end{thm}

\begin{coro}
$\pi(x+y) - \pi(x) \ll \frac{y}{\log\log y}$.
\begin{proof}
In example 1, $f \equiv 1$, and $|R_d| \ll 1$, and $X=y$. So
\[
W_p(z) = \prod_{p \leq z} \left(1-\frac{1}{p}\right) \ll (\log z)^{-1}
\]
and 
\[
\sum_{d | p(z)} |R_d| \ll \sum_{d|p(z)} 1 \leq 2^z
\]
So $\pi(x+y) - \pi(x) \ll \frac{y}{\log z} + 2^z \ll \frac{y}{\log \log y}$ if we choose $z=\log y$.
\end{proof}
\end{coro}

---Lecture 7---

For the previous corollary: take $A=\{x < n <\leq x+y\}$, $p=$ all primes, $z=\log y$. Then $\frac{y}{\log \log y} \gg S(A,P;z) = |\{x<n \leq x+y: p|n \implies p \geq \log y\} \geq \pi(x+y) - \pi(x) + O(\log y)$.

\subsection{Selberg's Sieve}
Sieve of E-L: $S(A;P,z) \leq XW + O(\sum_{d | P(z)} |R_d|)$.\\
The problem is that we have to consider $2^z$ many divisors of $P(z)$, so we get $2^z$ many error terms, which forces us to only take $z=\log y$.\\

$\bullet$ We can do a different sieve, and only consider those divisors of $P(t)$ which are \emph{small}, say $\leq D$.\\
The key part of E-L was $1_{(n,P(z))} = 1 = \sum_{d|(n,P(z))} \mu(d)$.\\
For an upper bound, it's enough to use \emph{any} function $F$, s.t. 
\[
F(n) \geq \left\{ \begin{array}{ll}
1 & n=1\\
0 & else
\end{array}
\right.
\]
Selberg's observation was that if $(\lambda_i)$ is any sequence of reals with $\lambda_1 = 1$, then $F(n) = (\sum_{d|n} \lambda_d)^2$ works: $F(1) = (\sum_{d|1}\lambda_d)^2 = \lambda_1^2 = 1$.

Assumption: $0 < f(p) < p$ if $p \in P$ (remember that $|A_p| = \frac{f(p)}{p} X + R_p$).

This lets us define a new multiplicative(?) function $g$ s.t.
\[
g(p) = \left(1-\frac{f(p)}{p}\right)^{-1}-1 = \frac{f(p)}{p-f(p)}
\]

\begin{thm} (3, Selberg's Sieve)\\
\[
\forall t S(A,P;z) \leq \frac{X}{G(t,z)} + \sum_{d | P(z), d<t^2} 3^{\omega(d)} |R_d|
\]
where $G(t,z) = \sum_{d|P(z), d<t} g(d)$.\\
Recall $W=\prod_{p \in P,p \leq z} (1-\frac{f(p)}{p})$, so expected size of $S(A,P;z)$ is $XW$.\\
Note thas, as $t \to \infty$, 
\[
G(t,z) &= \sum_{d | P(z)} g(d)\\
&= \prod_{p<z} (1+g(p))\\
&= \prod_{p<z}(1-\frac{f(p)}{p})^{-1}\\
&\approx \frac{1}{W}
\]
\end{thm}

\begin{coro} (4)\\
$\forall x,y$,
\[
\pi(x+y)-\pi(x) \ll \frac{y}{\log y}
\]
\begin{proof}
As before, $A = \{x <n \leq x+y\}$, $f(p) \equiv 1$, $R_d = O(1), X=y$.\\
Now apply Selberg's sieve instead. Main term: 
\[G(z,z) &= \sum_{d|P(z),d<z} \prod_{p | d} (p-1)^{-1} \\
&= \sum_{d = p_1...p_r < z} \prod \sum_{k \geq 1}^\infty \frac{1}{p_i^k}\\
&\geq \sum_{d<z} \frac{1}{d}\\
&\gg \log z
\]
But on the other hand, the second last line also equals
\[
&=\sum_i \sum_{k \geq 1, p_1...p_r < z}^\infty \frac{1}{p_1^{k_1}...p_r^{k_r}}\\
&= \sum_{n, \text{ square free part of n } <z} \frac{1}{n}
\]
($g(p)=\frac{1}{p-1} = \frac{1}{\varphi(p)}$, so $g(d) = \frac{1}{\varphi(d)}$).
So our main term is $\ll \frac{y}{\log z}$.\\
Note that $3^{\omega(d)} \leq \tau_3(d) \ll_\varepsilon d^\varepsilon$. so error term is $\ll_\varepsilon t^\varepsilon \sum_{d < t^2} 1 \ll t^{2+\varepsilon} = z^{2+\varepsilon} (t=z)$. So
\[
S(A,P;z) \ll \frac{y}{\log z} + z^{2+\varepsilon} \ll \frac{y}{\log y}
\]
(choose $z=y^{1/3}$).
\end{proof}
\end{coro}

\begin{proof} (of Selberg's Sieve)\\
Let $(\lambda_i)$ be a sequence of reals, with $\lambda_1 = 1$, to be chosen later. Then
\[
S(A,P;z) &= \sum_{n \in A} 1_{(n,P(z)) = 1}\\
&\leq \sum_{n \in A} (\sum_{d | (n,P(z))} \lambda_d)^2\\
&= \sum_{d,e | P(z)} \lambda_d \lambda_e \sum_{n \in A} 1_{d|n,e|n}\\
&= \sum_{d,e | P(z)} \lambda_d \lambda_e |A_{[d,e]}|\\
&= X \sum_{d,e | P(z)} \lambda_d \lambda_e \frac{f([d,e])}{[d,e]} + \sum_{d,e|P(z)} \lambda_d \lambda_e R_{[d,e]}
\]
We'll choose $\lambda_d$ s.t. $|\lambda_d| \leq 1$, and $\lambda_d = 0$ if $d \geq t$. Then
\[
\left|\sum_{d,e | P(z)} \lambda_d\lambda_e R_{[d,e]}\right| &\leq \sum_{d,e < t, d,e|P(z)} |R_{[d,e]}|\\
&\leq \sum_{n | P(z),n<t^2} | R_n | \sum_{d,e} 1_{[d,e]=n}
\]
and since $\sum_{d,e} 1_{[d,e]=n} = 3^{\omega(n)}$ (think of $n=p_1...p_r$ where $d=p_1...p_k$ and $e=p_j...p_r$ for $k \geq j$; so basically for each $p_i$ we have 3 choices: it's in $d$, in $e$, or in both) ($n$ square-free).\\
Let $V = \sum_{d,e|P(z)} \lambda_d \lambda_e \frac{f([d,e])}{[d,e]}$. Write $[d,e] = abc$ where $d=ab$, $e=bc$, and $(a,b) = (b,c) = (a,c) = 1$ (this is possible because $n$ is square-free).
\end{proof}

---Lecture 8 missing---

---Lecture 9---

Example class today, 330-5pm, mr14.

To finish the proof that $\pi_2(x) \ll \frac{x}{(\log x)^2}$, we need to show $G(z,z) \gg (\log z)^2$, where $G(z,z) = \sum_{d| P(z), d<z} g(d)$ and $g(2) = 0$ and $g(p) = \frac{2}{p-2}$.\\
First note that $g(p) \geq \frac{2}{p-1}$. So if $d$ is odd and square free, then $g(d) \geq \frac{2^{\omega(d)}}{\varphi(d)}$ (note that the numerator is equal to $\tau(d)$ for square-free integers).\\
Now write
\[
G(z,z) &= \sum_{d < z, d \text{ odd, square free}} \frac{2^{\omega(d)}}{\varphi(d)}\\
&\gg \sum_{d < z, d \text{ square free}} \frac{2^{\omega(d)}}{\varphi(d)}
\]
(the even  terms added in are only at most twice of the original sum, so it doesn't change the order). Now the above
\[
&=\sum_{d < z, d \text{square free}, d=p_1...p_r} 2^{\omega(d)} \prod_{i=1}^r (1/p_i+1/p_i^2+...)\\
&= \sum_{d < z, d=em^2, e \text{ square free}} 2^{\omega(d)}/d\\
&\geq \sum_{d < z} \frac{2^{\omega(d)}}{d}
\]
by partial summation, it's enough to show that $\sum_{d<z} 2^{\omega(d)} \gg z\log z$, because then above $\gg (\log z)^2$ as required (check).

Recall that, to show $\sum_{d<z} \tau(d) \gg z\log z$, we used that $\tau = 1*1$. So similarly we want to write $2^{\omega(n)} = \sum_{d|n} \mu(d) f(n/d)$ where $f$ is multiplicative.\\
Let's do some calculation: for $n=1$ we need $\mu(1)f(1)=1$, so $f(1) = 1$. For $n=p$ a prime, $2=f(p)-f(1) = f(p)-1$, so $f(p)=3$.\\
For $n=p^2$ a prime, $2=f(p^2)-f(p)$, so $f(p^2) = 5$...

Ok this probably doesn't work. Let's try something more general, say write it as $\sum_{d|n} f(d) g(n/d)$, where $f$ is multiplicative. Then\\
$\bullet$ $n=1$: $f(1)=g(1)=1$;\\
$\bullet$ $n=p$: $f(p)+g(p)=2$;\\
$\bullet$ $n=p^2$: $g(p^2)+f(p^2)+f(p)g(p) = 2$.

Say let's try $f=\tau$. So $g(p) = 0, g(p^2) = -1, g(p^k) = 0$ $\forall k \geq 3$.

So therefore 
\[
g(n) = \left\{\begin{array}{ll}
0 & n \text{ not a square}\\
\mu(d) & n=d^2
\end{array}
\right.
\]
and $2^{\omega(n)} = \sum_{d|n} \tau(d) g(n/d)$.\\
So (remember $\sum_{b \leq x} \tau(b) = x\log x + (2\gamma - 1) x + O(\sqrt{x})$)
\[
\sum_{d<z} 2^{\omega(d)} &= \sum_{a<z} g(a) \sum_{b \leq z/a} \tau(b)\\
&= \sum_{a < z} g(a) z/a \log (z/a) + c\sum_{a<z} g(a) z/a + \underbrace{O(z^{1/2} \sum_{a<z} 1/a^{1/2})}_{\ll z}\\
&= \sum_{d < z^{1/2}} \mu(d) z/d^2 \log z - \underbrace{2\sum_{d<z^{1/2}} \mu(d) z/d^2 \log d}_{\ll z\sum_{d<z^{1/2}} \log d/d^2 \ll z} + O(z)
\]
Note $\sum_{d<z^{1/2}} \frac{\mu(d)}{d^2} = c+O(\sum_{d>z^{1/2}} 1/d^2) = c+O(1/z^{1/2})$. So
\[
\sum_{d<z} 2^{\omega(d)} = cz\log z + O(z) \gg z\log z
\]

It remains to show that $c>0$. Either:\\
(1) Note LHS can't be $O(z)$;\\
(2) calculate the first couple of terms in the series;\\
(3) Note that $c=6/\pi^2 (=\frac{1}{\zeta(2)}) > 0$.

\subsection{Combinatorial Sieve}
Selberg is just an upper bound sieve (where we considered
\[
(\sum_{d|n} \lambda_d)^2 \geq \left\{
\begin{array}{ll}
1 & n=1\\
0 & else\\
\end{array}
\right.
\]
with $\lambda_i=1$). Now consider some inclusion-exclusion principle:
\[
S(A,P;z) = |A| - \sum_p |A_p| + \sum_{p,q} |A_{p,q}| - ...
\]
The idea of combinatorial sieve is to truncate the sieve process.

\begin{lemma} (Buchstab Formula)\\
$S(A,P;z) = |A| - \sum_{p | P(z)} S(A_p,P;p)$.
\begin{proof}
First notice that $|A| = S(A,P;z) + \sum_{p | P(z)} S(A_p,P;p)$: the first term is the number of $n \in A$ s.t. $p|n, p \in P \implies p \geq z$ by definition (denote this set by $S_1$); the summand of second term is the number of $n \in A$ s.t. $n=mp$, and $q | n, q \in P \implies q > p$ (denote this set by $S_p$ for each $p$).\\
Now note that every element $n \in A$ is either in $S_1$, or has some prime divisors from $P(z)$. If $p$ is the least such prime divisor, then $n \in S_p$. So this is a partition of $A$.
\end{proof}
\end{lemma}

Similarly we could prove 
\[
W(z) = 1-\sum_{p|P(z)} \frac{f(p)}{p} W(p)
\]
as $W(z) = \prod_{p | P(z)} (1-\frac{f(p)}{p})$.

\begin{coro}
For any $r \geq 1$, 
\[
S(A,P;z) = \sum_{d | P(z), \omega(d) < r} \mu(d) |A_d|+(-1)^r \sum_{d|P(z),\omega(d) = r} S(A_d,P;l(d))
\]
where $l(d)$ is the least prime divisor of $d$.
\begin{proof}
Induction on $r$. $r=1$ is just Buchstab formula. For the inductive step, use
\[
S(A_d,P;l(d)) = |A_d| - \sum_{p \in P, p < l(d)} S(A_{dp},P;p)
\]
and
\[
&(-1)^r \sum_{d|P(z), \omega(d)=r} (|A_d| - \sum_{p \in P, p < l(d)} S(A_{pd},P;p))\\
=&\sum_{d|p(z), \omega(d)=r} \mu(d) |A_d| + (-1)^{r+1} \sum_{e|P(z),\omega(e) = r+1} S(A_e,P;l(e))
\]
In particular, note that if $r$ is even, then
\[
S(A,P;z) \geq \sum_{d | P(z), \omega(d) < r} \mu(d) |A_d|
\]
Similarly, if $r$ is odd we get a similar bound in the $\leq$ direction.
\end{proof}
\end{coro}

\begin{thm} (Brun's Pure Sieve)\\
For $r \geq 6\log \frac{1}{W(z)}$, then 
\[
S(A,P;z) = XW(z) + O(2^{-r} X + \sum_{d | P(z), d \leq z^r} |R_d|)
\]
(Compare this to Eratostehen's sieve:
\[
S(A,P;z) = XW(z)  +O(\sum_{d|P(z)} |R_d|)
\]
)

---Lecture 10---

\begin{proof}
Recall that from the iterating Buchstab Formula, we have that, for any $r \geq 1$,
\[
S(A,P;x) &= \sum_{d | P(z), \omega(d) < r} \mu(d) |A_d| + (-1)^r \sum_{d|P(z), \omega(d) = r} S(A_d,P;l(d))\\
&= X \sum_{d | P(z), \omega(d) < r} \mu(d) \frac{f(d)}{d} + \sum_{d | P(z), \omega(d) < r} \mu(d) R_d + (-1)^r \sum ...
\]
by trivial bound $0 \leq S(A_d,P;l(d)) \leq |A_d| = X\frac{f(d)}{d} + R_d$. So above
\[
S(A,P;z) &= X\sum_{d | P(z), \omega(d) < r} \mu(d) \frac{f(d)}{d} + O(\sum_{d | P(z),\omega(d)<r} |R_d| + \sum_{d | P(z), \omega(d) = r} |A_d|)
\]

By Buchstab again, applied to $W(z)$, we have

\[
W(z) = \sum_{d|P(z), \omega(d) < r} \mu(d) \frac{f(d)}{d} + (-1)^r \sum_{d | P(z), \omega(d) = r} \mu(d) \frac{f(d)}{d} W(l(d))
\]
So
\[
S(A,P;z) = XW(z) + O\left(\sum_{d|P(z), \omega(d) < r} |R_d| + \sum_{d|P(z), \omega(d) = r} |A_d| + X\sum_{d|P(z), \omega(d) = r} \frac{f(d)}{d}\right)
\]
where we just use a crude bound that $W(l(d)) < 1$.\\
Error term:
\[
&= X \sum_{d | P(z), \omega(d) = r} \frac{f(d)}{d} + \sum_{d|P(z), \omega(d) \leq r} |R_d|\\
&\leq \sum_{d|P(z), d \leq z'} |R_d|
\]
because $d|P(z) = \prod_{p \in P, p < z} P$. It remains to show that
\[
\sum_{d|P(z), \omega(d) = r} \frac{f(d)}{d} \ll 2^{-r}
\]

Note that
\[
\sum_{d|P(x),\omega(d) = r} \frac{f(d)}{d} &= \sum_{p_1...p_r, p \in P, p_i < z} \frac{f(p_1)...f(p_r)}{p_1...p_r} \leq \frac{(\sum_{p|P(z)} \frac{f(p)}{p})^r}{r!}
\]
and we use $r' \geq \frac{r^r}{e^r}$ to then get
\[
\leq (\frac{e\sum_{p|P(z)} \frac{f(p)}{p}}{r})^r \ (\dagger)
\]
Now
\[
\sum_{p|P(z)} \frac{f(p)}{p} \leq \sum_{p|P(z)}-\log(1-\frac{f(p)}{p}) = -\log W(z)
\]
So if $r \geq 2e|\log W(z)|$, then ($\dagger$) is at most 
\[
(\frac{e|\log W(z)|}{r})^r \leq 2^{-r}
\]
and we're done ($2e<6$).
\end{proof}
\end{thm}

Note that we could easily improve this by being more careful at the constants, but those are less important; we just want to have the purest form of the combinatorial sieve.

Recall Selberg's Sieve shows $\pi_2(x) \ll \frac{x}{(\log x)^2}$, and now combinatorial sieve gives both upper and lower bound, so we might think it would give a lower bound for $\pi_2(x)$. However, in the twin prime sieve setting, recall that $W(z) \asymp \frac{1}{(\log z)^2}$, so in Brun's sieve we need to take $r \gg 2 \log \log z$.\\
If $r = C \log \log z$ for $C$ large enough, then $2^{-r} X \ll \frac{X}{(\log z)^{100}}$ (safe enough); the main term is $\gg \frac{x}{(\log z)^2}$; $|R_d| \ll 2^{\omega(d)} = d^{o(1)}$, so 
\[
\sum_{d|P(z),d \leq 2^r} |R_d| \ll 2^{r+o(1)} = z^{2 \log \log z} + o(1).
\]

For this to be $o(\frac{x}{(\log z)^2})$, we need to choose $z \approx \exp((\log x)^{1/4})$. We seem to have success, but in the end when we try to relate $S(A,P;z)$ and $\pi_2(x)$, we have LHS is $\{1 \leq n \leq x: p|n(n+2)$ then $p \gg (?) z = \exp((\log x)^{1/4})\}$ ($p \gg x^{1/2}$), but when we try to get a lower bound it is impossible to remove the extra stuff we have here.

\begin{coro}
For any $z \leq \exp(o((\frac{\log x}{\log \log x})^{1/2}))$,
\[
|\{1 \leq n \leq x: p|n \implies p \geq z\}| \sim e^{-\gamma} \frac{x}{\log z}
\]
\end{coro}

\begin{rem}
1) In particular: $z = (\log x)^A$ is allowed for any $A$, but $z=x^c$ for any $c >0$ is not allowed.\\
2) In particular, we can't count primes like this ($z=x^{1/2})$. Recall heuristic from before says if this asymptotic were correct for primes, then $\pi(x) \sim 2e^{-r} \frac{x}{\log x}$ (contradicts PNT: $2e^{-\gamma} = 1.12...$).
\end{rem}

\begin{proof}
Again, use $A=\{1 \leq n \leq x\}$, so $f(d) = 1$ and $|R_d| \ll 1$. Then $W(z) = \prod_{p < z} (1-\frac{1}{p}) \sim e^{-\gamma}{\log z}$. So
\[
S(A,P;z) &= |\{1 \leq n \leq x: p | n \implies p > z\}| \\
&= e^{-\gamma} \frac{x}{\log z} + o(\frac{x}{\log z}) + O(2^{-r} x + \sum_{d | P(z), d < 2^r} |R_d|)
\]
If $r \geq 6 |\log W(z)|$, so $r \geq 100\log\log z$ is certainly fine: we have in that caes
\[
2^{-r} x \leq (\log z)^{-(\log 2) 100} x = o(\frac{x}{\log z})
\]
and, choosing $r=\lceil 100\log\log z\rceil$
\[
\sum_{d | P(z), d \leq 2^r} |R_d| \ll \sum_{d \leq z^r} 1 \ll z^r \leq 2^{500 (\log z) \log\log z}
\]
(this course is very forgiving on constants). It remains to note that if $\log z = o((\frac{\log x}{\log \log x})) = \frac{(\log x)}{(\log \log x)} F(x)$, then
\[
\log z \log\log z &= o(\frac{\log x}{\log\log x} \cdot \log \log x)\\
&= o(\log x)
\]
So $2^{500 (\log\log z)\log z} \leq x^{1/10} = o(\frac{x}{\log z})$ if $x$ is large enough.
\end{proof}




\newpage

\section{Example Class 1}

We'll go through questions 2,3,5,1,4,6 (in that order).

\subsection{Question 2}
(a) 
\[
\sum_{n \leq x} \omega(n) &= \sum_{n \leq x} \sum_{p | n} 1\\
&= \sum_{p \leq x} \sum_{p|n \leq x} 1\\
&= \sum_{p \leq x} \lfloor \frac{x}{p} \rfloor\\
&= x\log\log x + O(x)
\]
using $\sum_{p \leq x} \frac{1}{p} = \log\log x + O(1)$, and $[x] = x+O(1)$ and number of $p\leq x$ is $O(x)$.

Try to avoid writing things like $O(1) \sum_{p\leq x} 1$. Sample replacement of it: $\sum_{p \leq x} O(1) = O(\sum_{p \leq x} 1)$.

(b) In general whenever you seem a sum like this, the first instinct should be to expand it. So we have
\[
&\sum_{n \leq x} |\omega(n) - \log\log x|^2 \ll x\log\log x\\
=&\sum_{n \leq x} \omega(n)^2 - 2\log\log x \sum_{n \leq x} \omega(n) + \lfloor x \rfloor (\log\log x)^2
\]
So it's enough to show that
\[
\sum_{n \leq x} \omega(n)^2 \leq x(\log\log x)^2 + O(x\log \log x)
\]
We write LHS as 
\[
\sum_{p,q \leq x} \sum_{n \leq x} 1_{p|n}1_{q|n} &= \sum_{p=q} \lfloor x/p \rfloor + \sum_{p \neq q} \lfloor \frac{x}{pq}\rfloor\\
&= \sum_{p,q} \lfloor \frac{x}{pq} \rfloor + O(x\log\log x)\\
&\leq x \sum_{p,q} \frac{1}{pq} + O(...)\\
&\leq x (\sum_p \frac{1}{p})^2 + O(...)
\]

(c) It's enough to show that $\sum_{n \leq x} |\log\log x-\log\log n|^2 \ll x\log\log x$ by noting that the sum is actually a metric. We could certainly expand it, but it's more work than what we need. The reason we are expanding above is because we have a mixture of something arithmetic and something analytic, so we can't do anything to it without expanding the square.

Note that if $x^{1/2} \leq n \leq x$, then $|\log\log x - \log\log n| = O(1)$. So the original sum
\[
&= \underbrace{\sum_{n \leq x^{1/2}}}_{O(x^{1/2} (\log\log x)^2} ... + \underbrace{\sum_{x^{1/2}\leq n \leq x}}_{O(x)} ...
\]

Now let $r(x)$ be the number of $n \leq x$ s.t. $|\omega(n) - \log\log n| > (\log \log x)^{3/4}$. Then 
$r(x) (\log\log x)^{3/2} \ll x\log\log x$, so $r(x) \ll \frac{x}{(\log\log x)^{1/2}} = o(x)$. (??)

For 'almost all' $n$, $\tau(n) \geq 2^{\omega(n)}$, and $\leq 2^{\Omega(n)}$ where $\Omega(n)$ counts all prime divisors rather than just the distinct ones.

\subsection{Question 3}

(a) Following lecture, we want something like
\[
\sum_{n \leq x} \frac{1}{n} &= \gamma + \log x - \frac{\{x\}}{x} + \int_x^\infty \frac{\{t\}}{t} dt\\
&= 1 - \frac{\{x\}} + \log x - \int_1^x \frac{\{t\}}{t^2} dt\\
&?= \gamma + \log x - \frac{\{x\}}{x} + \frac{1}{2x} + O(\frac{1}{x^2})
\]

So it's enough to show that 
\[
\left|\int_x^\infty \frac{\{t\}}{t^2} dt - \int_x^\infty \frac{1/2}{t^2} dt\right| \ll \frac{1}{x^2}
\]
Note that for $t \in [n,n+1)$,
\[
\left|\frac{1}{t^2} - \frac{1}{n^2}\right| \ll \frac{1}{n^3}
\]
So
\[
\int_n^{n+1} \frac{\{t\}}{t^2} dt &= \frac{1}{n^2} \int_n^{n+1} \{t\} dt + O(\frac{1}{n^3})\\
&= \frac{1}{2n^2} + O(\frac{1}{n^3})\\
&= \frac{1}{2} \int_n^{n+1} \frac{1}{t^2} dt + O(\frac{1}{n^3})\\
&= \frac{1}{2} \int_n^{n+1} (\frac{1}{t^2} + O(1/t^3)) dt
\]
So
\[
\int_x^\infty \frac{\{t\}}{t^2} dt = \frac{1}{2} \int_x^\infty \frac{1}{t^2} dt + O(\frac{1}{x^2})
\]

(b) (1) Using part (a) we get 
\[
\Delta(x) = x^{1/2} - 2\sum_{a \leq x^{1/2}} \{x/a\} + O(1)
\]
(2) 
\[
\int_0^x \Delta(t) dt \ll x
\]

We get $\frac{2}{3}x^{3/2}$ from the first term after integration, so we want the second term to have a main tern that cancels this out.

\subsection{Question 5}
(a) 
\[
\gamma &= -\int_0^\infty e^{-t} \log t dt\\
&= \lim_{N \to \infty} (\sum_{n=1}^N \frac{1}{n} - \log N)
\]
We write
\[
\frac{1}{n} = \int_I f_n(t) dt = \int_0^1 t^{n-1} dt
\]
Now
\[
\sum_{n=1}^N \frac{1}{n} &= \int_0^1 (1+t+...+t^{N-1}) dt\\
&=\int_0^1 \frac{1-t^N}{1-t} dt\\
&= \int_1^N \frac{1-(1-\frac{v}{N})^N}{v} dv
\]
So
\[
\gamma &= \lim_{n \to \infty} (-\int_1^N \frac{(1-v/N)^N}{v} dv)\\
&= -\int_1^\infty \frac{e^{-v}}{v} dv + \int_0^1 \frac{1-e^{-t}}{t} dt\\
&= \int_1^\infty e^{-t} \log t dt + \int_0^1 e^{-t} \log t dt
\]

(c) $\forall \delta>0$,
\[
\sum_p \frac{1}{p^{1+\delta}} + \log \delta - c + \gamma = \delta \int_2^\infty \frac{E(t)}{t^{1+\delta}} dt - \delta\int_1^2 \frac{\log\log t + c}{t^{1+\delta}}dt
\]
as $\delta \to 0$,
\[
\sum_p \frac{1}{p^{1+\delta}} + \log \delta \to c-\gamma
\]
We have $E(t) \ll \frac{1}{\log t}$, and $\delta \int_2^\infty \frac{1}{(\log t)t^{1+\delta}} dt \ll \delta^{1/2}$.

(e) Note that this will show
\[
\prod_{p \leq x} (1-1/p) \sim e^\gamma \log x
\]
Let 
\[
F(\delta) = \sum_p (\log (1-\frac{1}{p^{1+\delta}})+\frac{1}{p^{1+\delta}})
\]
converges uniformly. So $F(0) = \lim_{\delta \to 0} F(\delta)$.\\
Now 
\[
\sum_p \log (1-\frac{1}{p^{1+\delta}} = \log \zeta(1+\delta) \to -\log \delta
\]
as $\delta \to 0$ (we haven't done zeta function, but let's use it anyway) ($\log \zeta(1+\delta) + \log \delta) \to 0$ as $\delta \to 0$).

\subsection{Question 1}
We want to use induction and hyperbola method as well.\\
Note that $\tau_n = 1*\tau_{n-1}$. Write
\[
\sum_{n\leq x} \tau_k(n) &= \sum_{ab \leq x} \tau_{k-1} (b)\\
&= \sum_{a \leq x^{1/k}} \sum_{b \leq x/a} \tau_{k-1}(b) + \sum_{b \leq x^{1-1/k}} \tau_{k-1}(b) \lfloor x/b\rfloor - (\sum_{b \leq x^{1-1/k}} \tau_{k-1}(b))\lfloor x^{1/k} \rfloor\\
&=...
\]

Unfortunately we have no time for more, but feel free to ask now or later.

\end{document}
