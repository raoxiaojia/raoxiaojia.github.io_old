\documentclass[a4paper]{article}

\input{temp}

\setcounter{section}{-1}

\begin{document}

\title{Analytic Number Theory}

\maketitle

\newpage

\tableofcontents

\newpage

\section{Introduction}

---Lecture 1---

Lecturer: Thomas Bloom ($tb634@cam.ac.uk$, $www.thomasbloom.org/ant.html$)

Printed notes will be updated, but 1-2 weeks behind.

Example classes: weeks 3,5,7, tuesdays 330-5pm; prop-in sessions weeks 2,4,6,8. Rooms to be confirmed later.

What is analytic number theory? It's the study of numbers (regular integers, discrete) using analysis (real/complex, continuous) and some other quantitative questions.

For example, for the famous function $\pi(x)$, the number of primes no greater than $x$, we know $\pi(x) \sim \frac{x}{\log x}$.

Throughout this course, by \emph{numbers} we'll mean natural numbers excluding 0.

We can also ask how many twin primes there are, i.e. how many $p$ such that $p,p+2$ are both prime. This is not known yet (not even the finiteness); but from 2014, Zhang, Maynard, Polymath showed that there are infinitely many primes at most 246 apart, which is not that far from 2. The current guess is that the number is around $\frac{x}{(\log x)^2}$.

Another question we may ask: how many primes are there $\equiv a \pmod q$, $(a,q) = 1$. We know by Dirichlet's theorem that there are infinitely many.\\
A natural guess of the count is $\frac{1}{\phi(q)} \frac{x}{\log x}$, where $\phi(x)$ is the Euler Totient function. This is known to hold for small $q$.

In this course we'll talk about:\\
(1) Elementary techniques (real analysis);\\
(2) Sieve methods;\\
(3) Riemann zeta function/prime number theory (complex analysis);\\
(4) Primes in arithmetic progressions.

\newpage

\section{Elementary techniques}
Review of asymptotic notation:\\
$\bullet$ $f(x) = O(g(x))$ if there is $c>0$ s.t. $|f(x)| \leq c|g(x)|$ for all large enough $x$;\\
$\bullet$ $f \ll g$ is the same thing as $f=O(g)$. This also defines what $f \gg g$ means in the natural way;\\
$\bullet$ $f \sim g$ if $\lim_{x \to \infty} \frac{f(x)}{g(x)} = 1$ (i.e. $f=(1+o(1))g$);\\
$\bullet$ $f=o(g)$ if $\lim_{x \to \infty} \frac{f(x)}{g(x)} = 0$.

\subsection{Arithmetic functions}
Arithmetic functions are just functions $f:\N \to \C$; in other words, relabelling natural numbers with some complex numbers.\\
An important operation for multiplicative number theory ($fg = f(n)g(n)$) is multiplicative convolution,
$$f*g(n) = \sum_{ab=n}f(a)g(b)$$

Examples: $1(n) \equiv 1 \forall n$ (caution: $1$ is not the identity function, and $1*f \neq f$).\\
M\"{o}bius function:
\begin{equation*}
\begin{aligned}
\mu(n) = \left\{\begin{array}{ll}
(-1)^k & \text{ if } n=p_1...p_k\\
0 & \text{ if } n \text{ is divisible by a square} 
\end{array}
\right.
\end{aligned}
\end{equation*}
Liouville function: $\lambda(n) = (-1)^k$ if $n=p_1...p_k$ (primes not necessarily distinct),\\
Divisor function: $\tau(n) = $ number of $d$ s.t. $d|n = \sum_{ab = n} 1 = 1*1$. This is sometimes also known as $d(n)$.

An arithmetic function is multiplicative if $f(nm) = f(n)f(m)$ when $(n,m)=1$.\\
In particular, a multiplicative function is determined by its values on prime powers.

\begin{fact}
If $f,g$ are multiplicative, then so is $f*g$.\\
All the function we've seen so far ($\mu,\lambda,\tau,1$) are multiplicative.
\end{fact}

Non-example: $\log n$ is definitely not multiplicative.

\begin{fact} (M\"{o}bius inversion)\\
$1*f=g \iff \mu*g=f$. That is,
$$\sum_{a|n} f(d) = g(n) \forall n \iff \sum_{d|n} g(d)\mu(n/d) = f(n) \forall n$$
e.g.
\begin{equation*}
\begin{aligned}
\sum_{d|n}\mu(d) = \left\{\begin{array}{ll}
1 & n=1\\
0 & \text{else}
\end{array}
\right. = 1*\mu
\end{aligned}
\end{equation*}
is multiplicative: it's enough to check identity for primes powers.\\
If $n=p^k$ then $\{d|n\} = \{1,p,...,p^k\}$. So LHS=$1-1+0+0+...=0$, unless $k=0$ when LHS = $\mu(1) = 1$.

Our goal is to study primes. The first guess might be to work with
\begin{equation*}
\begin{aligned}
1_p(n) = \left\{\begin{array}{ll}
1 & n \text{ prime}\\
0 & \text{else}
\end{array}
\right.
\end{aligned}
\end{equation*}
(e.g. $\pi(x) = \sum_{1 \leq n \leq x} 1_p(n)$). Instead, we work with von Mangoldt funcion
\begin{equation*}
\begin{aligned}
\wedge(n) = \left\{\begin{array}{ll}
\log p & n \text{ is a prime power}\\
0 & \text{else}
\end{array}
\right.
\end{aligned}
\end{equation*}
(e.g. in a few lectures we'll look at $\psi(x) = \sum_{1\leq n \leq x} \wedge(n)$).
\end{fact}

\begin{lemma} (1)\\
$1*\wedge = \log$, and by M\"{o}bius inversion, $\mu*\log = \wedge$.\\
Note that it's easy to realize that $\wedge$ is not multiplicative, else $\log$ will be.
\begin{proof}
$1*\wedge(n) = \sum_{d | n} \wedge(d)$. So if $n=p_1^{k_1}...p_r^{k_r}$, then above
\begin{equation*}
\begin{aligned}
&=\sum_{i=1}^r \sum_{j=1}^{k_i} \wedge(p_i^j)\\
&=\sum_{i=1}^r \sum_{j=1}^{k_i} \log(p_i)\\
&= \sum_{i=1}^r k_i \log (p_i)\\
&= \log n
\end{aligned}
\end{equation*}
\end{proof}
\end{lemma}

Note that the above tells us
\begin{equation*}
\begin{aligned}
\wedge(n) &= \sum_{d|n} \mu(d) \log(n/d)\\
&=\log n \sum_{d|n}\mu(d) - \sum_{d|n} \mu(d)\log d\\
&= -\sum_{d|n} \mu(d)\log d
\end{aligned}
\end{equation*}
by the famous fact that $\sum_{d|n}\mu(d)=0$ unless $n=1$; but when $n=1$, $\log n = 0$.\\
Now we can try to evaluate
\begin{equation*}
\begin{aligned}
-\sum_{1 \leq n \leq x} \wedge(n) &= \sum_{1 \leq n \leq x} \sum_{d|n} \mu(d) \log d \\
&= -\sum_{d \leq x} \mu(d) \log d (\sum_{1 \leq n \leq x, d|n} 1)\ \text{ (reverse order of summation)}
\end{aligned}
\end{equation*}
But
$$\sum_{1 \leq n \leq x, d|n} 1 = \lfloor x/d \rfloor = x/d + O(1)$$
So we know the original sum is equal to
$$-x\sum_{d \leq x} \mu(d) \frac{\log d}{d} + O(\sum_{d \leq x} \mu(d) \log d)$$

---Lecutre 2---

Lecturer's favourite book: \emph{Multiplicative Number Theory}.

Room for example classes: MR14 (Tues 330-5pm, week 357).

\subsection{Summation}
Given an arithmetic function $f$, we can ask for estimates of $\sum_{1 \leq n \leq x} f(n)$.\\
We say that $f$ has \emph{average order $g$} if $\sum_{1 \leq n \leq x} f(n) \sim xg(x)$ (in some sense, the average size of $f$ is $g$).

For example, if $f \equiv 1$, then $\sum_{1 \leq n \leq x} f(n) = \lfloor x \rfloor = x+O(1) \sim x$. So the average order of $1$ is $1$ (makes a lot of sense).\\
A slightly less trivial example is the identity function $f(n) = n$: we have $\sum_{1 \leq n \leq x} n \sim \frac{x^2}{2}$, so the average order of $n$ is $n/2$.

\begin{lemma} (1, Partial summation)\\
If $(a_n)$ is a sequence of complex numbers, and $f$ is s.t. $f'$ is continuous. Then $\sum_{1 \leq n \leq x} a_n f(n) = A(x) f(x) - \int_1^x A(t) f'(t) dt$, where $A(x) = \sum_{1 \leq n \leq x} a_n$.\\
We can see that this is a discrete version of integration by parts.
\begin{proof}
Suppose $x=N$ is an integer. Note that $a_n = A(n) - A(n-1)$. So
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq N} a_nf(n) &= \sum_{1 \leq n \leq N} f(n) (A(n)-A(n-1))\\
&= A(N)f(N) - \sum_{n=1}^{N-1}A(n) (f(n+1)-f(n)) \text{ using } A(0)=0
\end{aligned}
\end{equation*}
Now $f(n+1)-f(n) = \int_n^{n+1} f'(t)dt$. So
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq N} a_n f(n) &= A(N)f(N) - \sum_{n=1}^{N-1} A(n) \int_n^{n+1} f'(t) dt\\
&= A(N)f(N) - \int_1^N A(t) f'(t) dt
\end{aligned}
\end{equation*}
To be complete, we should also consider the case where $x$ is not an integer. But if $N=\lfloor x \rfloor$,
\begin{equation*}
\begin{aligned}
A(x) f(x) &= A(N)f(x)\\
&=A(N)\left(f(N)+\int_N^x f'(t)dt\right)
\end{aligned}
\end{equation*}
\end{proof}
\end{lemma}

\begin{lemma} (2)\\
$$\sum_{1 \leq n \leq x} \frac{1}{n} = \log x + \gamma + O\left(\frac{1}{x}\right)$$
where $\gamma$ is some constant.
\begin{proof}
Apply partial summation with $f(x)=\frac{1}{x}$ and $a_n \equiv 1$, so $A(x) = \lfloor x \rfloor$. Then, writing $\lfloor t \rfloor = t - \{t\}$,
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq x} \frac{1}{n} &= \frac{\lfloor x \rfloor}{x} + \int_1^x \frac{\lfloor t \rfloor}{t^2} dt\\
&= 1 + O\left(\frac{1}{x}\right) + \int_1^x \frac{1}{t} dt - \int_1^x \frac{\{t\}}{t^2} dt\\
&= 1+O\left(\frac{1}{x}\right) + \log x - \int_1^\infty \frac{\{t\}}{t^2} dt + \int_x^\infty \frac{\{t\}}{t^2} dt\\
&=\gamma + O\left(\frac{1}{x}\right) + \log x + O\left(\frac{1}{x}\right)\\
&= \log x + \gamma + O\left(\frac{1}{x}\right)
\end{aligned}
\end{equation*}
where at the penultimate step we bound the error term by 
\begin{equation*}
\begin{aligned}
\int_x^\infty \frac{\{t\}}{t^2} dt &\leq \int_x^\infty \frac{1}{t^2} dt\\
&\leq \frac{1}{x}
\end{aligned}
\end{equation*}
and we actually know $\gamma = 1 - \int_1^\infty \frac{\{t\}}{t^2} dt$.\\
This $\gamma$ is called Euler's constant (Euler-Mascheroni).\\
We know very little about this constant: we only know $\gamma=0.577...$, and we don't even know if $\gamma$ is irrational.
\end{proof}
\end{lemma}

\begin{lemma} (3)\\
$$\sum_{1 \leq n \leq x} \log n = x\log x - x + O(\log x)$$
\begin{proof}
Use partial summation again, with $f(x) = \log x$ and $a_n=1$, so $A(x) = \lfloor x \rfloor$:
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq x} \log n &= \lfloor x \rfloor \log x - \int_1^x \frac{\lfloor t \rfloor}{t} dt\\
&= x \log x + O(\log x) - \int_1^x 1 dt + O(\int_1^x \frac{1}{t} dt)\\
&= x\log x - x + O(\log x)
\end{aligned}
\end{equation*}
\end{proof}
\end{lemma}

\subsection{Dinsar function}
Recall that $\tau(n) = 1*1(n) =\sum_{d|n} 1$.

\begin{thm} (4)\\
$$\sum_{1 \leq n \leq x} \tau(n) = x\log x + (2\gamma - 1) x + O(x^{1/2})$$
So average order of $\tau$ is $\log x$.
\begin{proof}
Note that we won't apply partial summation here: PS allows to get $\sum a_n f(n)$ from knowledge of $\sum a_n$; but $\tau(n)$ here is not differentiable, so PS is not going to apply.
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq x} \tau(n) &= \sum_{1 \leq n \leq x} \sum_{d|n} 1\\
&= \sum_{1 \leq d \leq x} \sum_{1 \leq n \leq x, d|n} 1\\
&= \sum_{1 \leq d \leq x} \lfloor \frac{x}{d} \rfloor\\
&= \sum_{1 \leq d \leq x} \frac{x}{d} + O(x)\\
&= x \sum_{1 \leq d \leq x} \frac{1}{d} + O(x)\\
&= x\log x + \gamma x + O(x) 
\end{aligned}
\end{equation*}
where we applied lemma 2 at the last step. This is all correct, but the error term is larger than what we wanted. However, we have indeed prove that the average order of $\tau(x)$ is $\log x$.\\
To reduce error term, we use (Dirichlet's) hyperbola trick:
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq x} \tau(n) &= \sum_{1 \leq n \leq x} \sum_{ab = n} 1\\
&= \sum_{ab \leq x} 1\\
&= \sum_{a \leq x} \sum_{b \leq \frac{x}{a}} 1
\end{aligned}
\end{equation*}
Note that now we're just counting number of integer points below the hyperbola $xy=n$ (relabelling variables).\\
When summing over $ab \leq x$, we can sum over $a,b \leq x^{1/2}$ separately, then subtract the repetition off. Then
\begin{equation*}
\begin{aligned}
\sum_{1 \leq n \leq x} \tau (n) &= \sum_{a \leq x^{1/2}}\sum_{b \leq \frac{x}{a}} 1 + \sum_{b \leq x^{1/2}} \sum_{a \leq \frac{x}{b}} 1 - \sum_{a,b \leq x^{1/2}} 1\\
&= 2 \sum_{a \leq x^{1/2}} \lfloor \frac{x}{a} \rfloor - \lfloor x^{1/2} \rfloor^2\\
&= 2 \sum_{a \leq x^{1/2}} \frac{x}{a} + O(x^{1/2}) - x + O(x^{1/2})
\end{aligned}
\end{equation*}
by noting that $\lfloor x^{1/2}\rfloor^2 = (x^{1/2} + O(1))^2$. Now the above equals
\begin{equation*}
\begin{aligned}
&=2x\log x^{1/2} + 2\gamma x - x + O(x^{1/2})\\
&= x\log x + (2\gamma-1) x + O(x^{1/2})
\end{aligned}
\end{equation*}
\end{proof}

Improving this $O(x^{1/2})$ error term is a famous and hard problem. We should probably get $O(x^{1/4+\varepsilon})$, but this is open. The best known result is $O(x^{0.3149...})$.
\end{thm}

Note that this does \emph{not} mean that $\tau(n) \ll \log n$. The average order is small doesn't say about the individual values being small.

We'll state the theorem we're proving and prove it in the next lecture:
\begin{thm} (5)\\
$$\tau(n) \leq n^{O(\frac{1}{\log\log n})}$$
In particular, $\tau(n) \ll_\varepsilon n^\varepsilon$ $\forall \varepsilon > 0$.

---Lecture 3---
\begin{proof}
    $\tau$ is multiplicative, so it's enough to calculate at prime powers.\\
    Now, $\tau(p^k) = k+1$. So if $n=p_1^{k_1}...p_r^{k_r}$, thjen $\tau(n) = \prod_{i=1}^r (k_i+1)$.\\
    Let $\varepsilon$ be chosen later, and consider $\frac{\tau(n)}{n^\varepsilon} = \prod_{i=1}^r \frac{k_i+1}{p_i^{k_i\varepsilon}}$. Note as $p \to \infty$, $\frac{k+1}{p^{k\varepsilon}} \to 0$.\\
    In particular, if $p \geq 2^{1/\varepsilon}$, then $\frac{k+1}{p^{k\varepsilon}} \leq \frac{k+1}{2^k} \leq 1$. What about for small $p$? We can't do better than $p \geq 2$(?).\\
    In this case, $\frac{k+1}{p^{k\varepsilon}} \leq \frac{k+1}{2^{k\varepsilon}} \leq \frac{1}{\varepsilon}$ (as $x+\frac{1}{2} \leq 2^x \implies \varepsilon k + \varepsilon \leq 2^{k\varepsilon} \forall x \geq 0$), for $\varepsilon \leq 1/2$.\\
    So
    \[
        \frac{\tau(n)}{n^\varepsilon} \leq \prod_{i=1,_i < 2^{1/\varepsilon}}^r \frac{k_i+1}{p^{k_i \varepsilon}} \leq (1/\varepsilon)2^{1/\varepsilon}
    \]
    Now choose optimal $\varepsilon$:\\
    (trick!) if you want to choose $x$ to minimise $f(xx)+g(x)$, choose $x$ s.t. $f(x) = g(x)$.\\
    So here, $\tau(n) \leq n^\varepsilon \varepsilon^{-2^{1\varepsilon}} = exp(\varepsilon \log n + 2^{1/\varepsilon} \log 1/\varepsilon)$.\\
    Choose $\varepsilon$ s.t. $\log n \approx 2^{1/\varepsilon}$, i.e. $\varepsilon = \frac{1}{\log\log n}$. So
    \[
        \tau(n) &\leq n^{1/\log\log n} (\log\log n)^{2^{\log\log n}}\\
        &= n^{1/\log\log n} e^{(\log n)^{\log 2} \log \log \log n}\\
        &\leq n^{O(\frac{1}{\log \log n})} 
    \]
\end{proof}
\end{thm}

\subsection{Estimates for the Primes}

Recall $\pi(x)$ is the number of primes $\leq x = \sum_{1 \leq n \leq x} 1_p(n)$, and $\psi(x) = \sum_{1 \leq n \leq x} \Lambda(n)$. The prime number theory states that $\pi(x) \sim \frac{x}{\log x}$, or equivalently $\psi(x) \sim x$ (justified later).\\
It was 1850 before the correct magnitude of $\pi(x)$ was proved. Chebyshev showed that $\pi(x) \asymp x/\log x$, where $f \asymp g$ means $g \ll f \ll g$.

\begin{thm} (6, Chebyshev)\\
    $\psi(x) \asymp x$.\\
    We'll show below that $(\log 2) x \leq \psi(x) \leq (\log 4) x$.
    \begin{proof}
        First we'll prove the lower bound. Recall $1 *\Lambda = \log$, i.e. $\sum_{ab = n} \Lambda(a) = \log n$. The (genuine) trick is to find a sum $\Sigma$ s.t. $\varepsilon \leq 1$. We'll use the identity $\lfloor x \rfloor \leq 2 \lfloor \frac{x}{2} \rfloor + 1 \forall x \geq 0$. Why? Say $\frac{x}{2} = n+\theta$, $\theta \in [0,1)$ Then $\lfloor \frac{x}{2} \rfloor = n$, and $x = 2n+2\theta$, and so $\lfloor x \rfloor = 2n$, or at most $2n+1$.\\
        So
        \[
            \psi(x) &\geq \sum_{n \leq x} \Lambda(n) (\lfloor \frac{x}{n} \rfloor - 2\lfloor \frac{x}{2n} \rfloor)\\
            &= \sum_{n \leq x} \Lambda(n) \sum_{m \leq x/n} 1 - 2 \sum_{n \leq x} \Lambda(n) \sum_{m \leq \frac{x}{2n}} 1\\
            &= \sum_{nm \leq x} \Lambda(n) - 2\sum_{nm \leq x/2} \Lambda(n), \text{ write } d = nm,\\
            &= \sum_{d \leq x} 1 *\Lambda(d) - 2 \sum_{d \leq x/2} 1 * \Lambda(d)\\
            &= \sum_{d \leq x} \log d - 2 \sum_{d \leq x/2} \log d\\
            &=x\log x - x + O(\log x) - 2(\frac{x}{2} \log \frac{x}{2} - \frac{x}{2} + O(\log x))\\
            &= (\log 2) x + O(\log x) \gg x
        \]
        For the upper bound, note that $\lfloor x \rfloor = 2\lfloor x/2 \rfloor + 1$ for $x \in (1,2)$, so
        $$\sum_{x/2 < n < x} \Lambda(n) = \sum_{x/2 < n < x} \Lambda(n) (\lfloor x/n \rfloor - 2 \lfloor x/2n \rfloor) \leq \sum_{1 \leq n \leq x} \Lambda(n) (\lfloor x/n \rfloor - 2\lfloor x/2n \rfloor)$$
        so $\psi(x) - \psi(x/2) \leq (\log 2) x + O(\log x)$.\\
        So $\psi(x) = (\psi(x) - \psi(x/2)) + (\psi(x/2)-\psi(x/4))+... \leq \log 2 (x+x/2+x/4+...) = (2\log 2) x$ (note only $\log x$ error terms at most).
    \end{proof}
\end{thm}

\begin{lemma} (7)\\
    \[
        \sum_{p \leq x, p \text{ primes}} \frac{\log p}{p} = \log x + O(1)
    \]
    \begin{proof}
        Recall that $\log = 1 * \Lambda$. So
        \[
            \sum_{n \leq x} \log n &= \sum_{ab \leq x} \Lambda(a)\\
            &= \sum_{a \leq x} \Lambda(a) \sum_{b \leq x/a} 1\\
            &= \sum_{a \leq x} \Lambda(a) \lfloor x/a \rfloor \\
            &= x \sum_{a \leq x} \frac{\Lambda(a)}{a} + O(\psi(x))\\
            &= x \sum_{a \leq x} \frac{\Lambda(a)}{a} + O(x)
        \]
        But $\sum_{n \leq x} \log n = x\log x - x + O(\log x)$. So
        \[
            \sum_{n \leq x} \frac{\Lambda(n)}{n} = \log x - 1 + O(\frac{\log x}{x}) + O(1) + \log x + O(1)
        \]
        It remains to note that 
        \[
            \sum_{p \leq x}\sum_{n=2}^\infty \frac{\log p}{p^n} &= \sum_{p \leq x} \log p \sum_{k=2}^\infty \frac{1}{p^k} \\
            &= \sum_{p \leq x} \frac{\log p}{p^2-p}\\
            &\leq \sum_{p=2}^\infty \frac{1}{p^{3/2}} = O(1)
        \]
        So $\sum_{n \;eq x} \frac{\Lambda(n)}{n} = \sum_{p \leq x} \frac{\log p}{p}+O(1)$.
    \end{proof}
\end{lemma}

\end{document}
