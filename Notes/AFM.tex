\documentclass[a4paper]{article}

\input{temp}

\setcounter{section}{-1}

\begin{document}

\title{Advanced Financial Models}

\maketitle

\newpage

\tableofcontents

\newpage

\section{Introduction}

$www.staslab.cam.ac.uk/~mike/AFM/$ for course material. However lecture notes only come after lectures, so taking notes is still necessary..

$m.tehranchi@statslab.cam.ac.uk$

Assumptions for this course:\\
No dividends, zero tick size (continuous), no transaction costs, no short-selling constraints, infinitely divisible assets, no bid-ask spread, infinite market depth, agents have preferences for expected utility.

\newpage

\section{Discrete time models}

We'll assume there are $n$ assets with price $P_t^i$ at time $t$ for asset $i$. Apparently $P_t^i$ is a random variable on some probability space $(\Omega,\mathcal{F},\P)$.

We'll use the notation $P=(P_t^1,...,P_t^n)_{t \geq 0}$ which is a $n$-dimensional stochastic process.

Information available at time $t$ is modelled by a $\sigma$-algebra $\mathcal{F}_t \subseteq \mathcal{F}$.

The assumption will be $\mathcal{F}_s \subseteq \mathcal{F}_t$ for $s \leq t$ (in other words, $\mathcal{F}$ is a filtration):

\begin{defi} (Filtration)\\
A \emph{Filtration} is a collection of $\sigma$-algebra $(\mathcal{F}_t)_{t \geq 0}$ such that $\mathcal{F}_s \subseteq \mathcal{F}_t$ for $s \leq t$.
\end{defi}

We'll assume that $\mathcal{F}_0$ is trivial, i.e. if $A$ is $\mathcal{F}_0$ measure then $\mathbb{P} = 0$ or $1$. As a result $P_0^1,...,P_0^n$ are constants.

We assume that $(P_t)_{t \geq 0}$ is adapted to the filtration, i.e. $P_t$ is $\mathcal{F}_t$-measurable for all $t \geq 0$. Usually we assume the filtration is generated by $P$ itself (so all the information is in the price).

Let $c_t$ be the amount consumed at time $t$ which will be a $\mathcal{F}_t$-measurable scalar, $H_t = (H_t^1,...,H_t^n)$ be the vector of portfolio weights, so $H_t^i$ is the number of shares held at $(t-1,t]$ (remember we are in discrete time), which will be $\mathcal{F}_{t-1}$-measurable. $(c_t)_{t \geq 0}$ is adapted ($\mathcal{F}_t$-measurable), $(H_t)_{t \geq 1}$ is predictable/previsible ($\mathcal{F}_{t-1}$-measurable, $n$-dimensional. 

\begin{defi}
The process $(c,H)$ is self-financing if $H_t\cdot P_t = c_t+H_{t+1} \cdot P_t$ for all $t \geq 1$.
\end{defi}

For example, $X_0$ be the initial wealth, $X_0-c_0$ is the post-consumption wealth ($=H_1 \cdot P_0$), $X_1=H_1 \cdot P_1$ is the pre-consumption wealth at time 1, $X_1-c_1$ is the post consumption wealth (which is $H_2\cdot P_1$. In other words, at any specific time, consumption takes place and then price updates.

Background assumption on behaviour of an agent:\\
Say $c^2$ is preffered to $c^1$ iff $\E U(c_0^1,c_1^1,...) < \E U(c_0^2,c_1^2,...)$ where $U$ is some investor utility function, which is increasing in all $c_i$, concave (so risk-avert)

\begin{defi}
An arbitrage is a self-financing investment-consumption strategy $(c,H)$ such that there exists a non-random time $T>0$ s.t. $c_0 = -H_1 \cdot P_0$, $c_t = (H_t - H_{t+1}) \cdot P_t$ for $1 \leq t \leq T-1$, and $c_T =H_T \cdot P_T$ (in words, with initial wealth $X_0 = 0$ and post-consumption wealth at $T$ $X_T-C_T=0$), that $\P(c_t \geq 0)$ for all $0 \leq t \leq T) = 1$, and $\P(c_t > 0$ for some $0 \leq t \leq T) > 0$.
\end{defi}

Suppose $(c^1,H^1)$ is self-financing with iniital wealth $X_0$, $(c^2,H^2) = (c^1,H^1) + (c,H)$, where $(c,H)$ is an arbitrage. Then $c^2$ is preferred to $c^1$.

The inverstor who believes there is an arbitrage would have no optimal investment-consumption policy.

Even further background assumption: the market is in equillibrium (supply = demand).

\begin{defi}
Given the market model, a martingale deflator is positive adapted process $(Y_t)_{t \geq 0}$ such that $(Y_t \cdot P_t)_{t \geq 0}$ is a martingale.
\end{defi}

\begin{thm} (First fundamental theorem of asset pricing)\\
The market has no arbitrage if and only if there exists a martingale deflator.
\end{thm}

\begin{defi}
Given an $(\Omega,\mathcal{F},\P)$-integrable $X$ ($\E|X| < \infty$), and $\mathcal{G} \subseteq \mathcal{F}$) a sub-$\sigma$-algebra of $\mathcal{F}$, a conditional expectation of $X$ given $\mathcal{G}$ is an integrable $Y$ that is $\mathcal{G}$-measurable and such that $\E(X 1_G) = \E(Y 1_G)$ for all $G \in \mathcal{G}$.
\end{defi}

\begin{thm}
The conditional expectations exist and are unique in the sense that, if $Y^1,Y^2$ are both conditional expecations, then $Y^1=Y^2$ almost surely.
\end{thm}

We'll use the notation $Y = \E(X|\mathcal{G})$.

\begin{eg}
Let $(G_n)_n$ be a partition of $\Omega$, $\mathcal{G} = \sigma({G_n})$. Then $\E(X|\mathcal{G})(\omega) = \frac{\E(X1_{G_n})}{\P(G_n)} = \E(X|G_n)$ if $\omega \in G_n$ and $\P(G_n)>0$, or anything else if $\P(G_n) = 0$ is a valid conditional expectation.
\end{eg}

\begin{thm}
    Suppose we have a probability space $(\Omega,\mathcal{F},\P)$ with $\mathcal{G} \subseteq \mathcal{F}$ a sub-$\sigma$-algebra, and assume all conditional expectations we need exist, i.e. all random variables are integrable.\\
    $\bullet$ 1. Linearity: $\E(aX+bY|\mathcal{G}) = a\E(X|\mathcal{G})+b\E(Y|\mathcal{G})$ $\forall a,b \in \R$;\\
    $\bullet$ 2. Positivity: If $X \geq 0$ a.s., then $\E(X|\mathcal{G}) \geq 0$ a.s.; furthermore, if $\E(X|\mathcal{G}) = 0$ a.s., then $X=0$ a.s..\\
    $\bullet$ 3. Jensen's inequality: If $f$ is convex, then $\E(f(X)|\mathcal{G}) \geq f(\E(X|\mathcal{G}))$ a.s. (here we obviously assume $f$ is integrable).\\
    $\bullet$ 4. Monotone convergence: If $X_n \geq 0$ $\forall n$ a.s. and $X_n \nearrow X$ a.s., then $\E(X_n | \mathcal{G}) \nearrow \E(X|\mathcal{G})$.\\
    $\bullet$ 5. Fatou's lemma: If $X_n \geq 0$, then $\liminf \E(X_n|\mathcal{G}) \geq \E(\liminf X_n|\mathcal{G})$.\\
    $\bullet$ 6. Dominated convergence: If $\E (\sup |X_n|) < \infty$ and $X_n \to X$ a.s., then $\E(X_n | \mathcal{G}) \to \E(X|\mathcal{G})$ a.s..\\
    The derivation of the above are similar to that of normal expectations. Now let's introduce something that's only for conditional expectations:\\
    $\bullet$ 7. If $X$ and $\mathcal{G}$ are \emph{independent}, i.e. $\{X \leq x\}$ and $G$ are independent for all $x \in \R$, $G \in \mathcal{G}$, then $\E(X|\mathcal{G}) = \E(X)$.\\
    $\bullet$ 8. Slot property: If $X$ and $XY$ are integrable, $Y$ is $\mathcal{G}$-measurable, then $\E(XY|\mathcal{G}) = Y\E(X|\mathcal{G})$. In particular, $\E(Y|\mathcal{G}) = Y$.\\
    $\bullet$ 9. Tower property: If $\mathcal{H} \subseteq \mathcal{G} \subseteq \mathcal{F}$, then
    \begin{equation*}
        \begin{aligned}
            \E\left(E(X|\mathcal{G})|\mathcal{H}\right) = \E\left(\E(X|\mathcal{H})|\mathcal{G}\right) = \E(X|\mathcal{H})
        \end{aligned}
    \end{equation*}
\end{thm}

\begin{defi}
    Given $(\Omega,\mathcal{F},\P)$ and filtration $(\mathcal{F}_t)_{t \geq 0}$, a martingale $\mathcal{M} =(\mathcal{M}_t)_{t \geq 0}$ is an adapted process (i.e. $\mathcal{M}_t is \mathcal{F}_t$-measurable), and integrable process (i.e $\E(|\mathcal{M}_t)<\infty \forall t$), and $\E(\mathcal{M}_t|\mathcal{F_s}) =\mathcal{M}_s$ for $0 \leq s \leq t$.
\end{defi}

\begin{rem}
    This definition is the same in both discrete and continuous time.
\end{rem}

\begin{prop}
In discrete time, an integrable adapted process $(\mathcal{M}_t)_{t \geq 0}$ is a martingale iff $\E(\mathcal{M}_{t+1}|\mathcal{F}_t) = \mathcal{M}_t$ for all $t \geq 0$.
\begin{proof}
    If $\mathcal{M}$ is a martingale then this condition holds trivially by definition.\\
    Now suppose $\E(\mathcal{M}_{t+1}|\mathcal{F}_t) = \mathcal{M}_t$ $\forall t \geq 0$, we claim $\E(\mathcal{M}_T | \mathcal{F}_t) = \mathcal{M}_t$ for all $T \geq t$. Prove by induction:\\
    This is true for $T=t+1$. Now $\E(\mathcal{M}_{T+1}|\mathcal{F}_t) = \E(\E(\mathcal{M}_{T+1}|\mathcal{F}_T)|\mathcal{F}_t) = \E(\mathcal{M}_T|\mathcal{F}_t)$ by tower property, so done.
\end{proof}
\end{prop}

\begin{eg}
    1. (Forward construction) Given $\xi_1,\xi_2,...$ independent and integrable, $\E(\xi_n)=0 \forall n$, $S_0=0$ and $S_t = \xi_1+...+\xi_t$ for $t \geq 1$. Then $(S_t)_{t \geq 0}$ is a martingale (relative to the filtration generated by $\xi_i$ ,i.e. $\mathcal{F} =\sigma(\xi_1,...\xi_t)$).
    \begin{proof}
        Adaptedness and integrability are easy (measurability and integrability are preserved by additions);\\
        Now
        \begin{equation*}
            \begin{aligned}
                \E(S_{t+1}|\mathcal{F}_t) &= \E(S_t+\xi_{t+1} | \mathcal{F}_t)\\
                &= \E(S_t|\mathcal{F}_t) + \E(\xi_{t+1}|\mathcal{F}_t)\\
                &= S_t+\E(\xi_{t+1}) = S_t
            \end{aligned}
        \end{equation*}
        we've used that $S_t$ is $\mathcal{F}_t$-measurable and the independence of $\xi_i$.
    \end{proof}

    2. (Backward construction) Given $X$ integrable, and a filtration $(\mathcal{F}_t)_{t \geq 0}$, let
    \begin{equation*}
        \begin{aligned}
            M_t = \E(X|\mathcal{F}_t)
        \end{aligned}
    \end{equation*}
    then $(M_t)_{t \geq 0}$ is a martingale.
    \begin{proof}
        As before we don'e have to do adaptedness and integrability as conditional expectations are integrable and adapted. Now
        \begin{equation*}
            \begin{aligned}
                \E(M_t | \mathcal{F}_s) = \E(\E(X|\mathcal{F}_t)|\mathcal{F}_s) = \E(X|\mathcal{F}_s) = M_s \forall t>s
            \end{aligned}
        \end{equation*}
        by tower property.
    \end{proof}
\end{eg}

\end{document}
